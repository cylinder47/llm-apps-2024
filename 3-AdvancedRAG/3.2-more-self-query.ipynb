{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 3.2 More self-query\n",
   "id": "819b5628dd0a73c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Setup\n",
    "\n",
    "### Install dependencies"
   ],
   "id": "afc17ba4fdf4a2e7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%pip install python-dotenv~=1.0 docarray~=0.40.0 pypdf~=5.1 --upgrade --quiet\n",
    "%pip install chromadb~=0.5.18 sentence-transformers~=3.3 --upgrade --quiet \n",
    "%pip install langchain~=0.3.7 langchain_openai~=0.2.6 langchain_community~=0.3.5 langchain-chroma~=0.1.4 langchainhub~=0.1.21 --upgrade --quiet\n",
    "\n",
    "# If running locally, you can do this instead:\n",
    "#%pip install -r ../requirements.txt"
   ],
   "id": "c1ebca0224805b6f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Load environment variables",
   "id": "1c9b2c415abbd4a8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "# If running in Google Colab, you can use this code instead:\n",
    "# from google.colab import userdata\n",
    "# os.environ[\"AZURE_OPENAI_API_KEY\"] = userdata.get(\"AZURE_OPENAI_API_KEY\")\n",
    "# os.environ[\"AZURE_OPENAI_ENDPOINT\"] = userdata.get(\"AZURE_OPENAI_ENDPOINT\")"
   ],
   "id": "64e2a708fa7cc1ee",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Setup models",
   "id": "f186ba7b4d2f41af"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain_openai import AzureChatOpenAI, AzureOpenAIEmbeddings\n",
    "api_version = \"2024-10-01-preview\"\n",
    "llm = AzureChatOpenAI(deployment_name=\"gpt-4o\", temperature=0.0, openai_api_version=api_version)\n",
    "embedding_model = AzureOpenAIEmbeddings(model=\"text-embedding-3-large\", openai_api_version=api_version)"
   ],
   "id": "ccc30d62c733a213",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Setup LangSmith tracing for this notebook",
   "id": "3d1d19158f7a3310"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "# API key etc is in the .env file\n",
    "# my_name = \"Totoro\"\n",
    "# os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "# os.environ[\"LANGCHAIN_PROJECT\"] = f\"tokyo24-test-{my_name}\""
   ],
   "id": "63b3816be3d5671b",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c0bc3390-4bed-49d3-96ce-072badb4110b",
   "metadata": {},
   "source": [
    "## How to do \"self-querying\" retrieval\n",
    "\n",
    "**_Info_**\n",
    "\n",
    ">Head to [Integrations](https://python.langchain.com/docs/integrations/retrievers/self_query/) for documentation on vector stores with built-in support for self-querying.\n",
    "\n",
    "\n",
    "A self-querying retriever is one that, as the name suggests, has the ability to query itself. Specifically, given any natural language query, the retriever uses a query-constructing LLM chain to write a structured query and then applies that structured query to its underlying VectorStore. This allows the retriever to not only use the user-input query for semantic similarity comparison with the contents of stored documents but to also extract filters from the user query on the metadata of stored documents and to execute those filters.\n",
    "\n",
    "![](https://github.com/langchain-ai/langchain/blob/master/docs/static/img/self_querying.jpg?raw=true)\n",
    "\n",
    "## Get started\n",
    "For demonstration purposes we'll use a `Chroma` vector store. We've created a small demo set of documents that contain summaries of movies.\n",
    "\n",
    "**Note:** The self-query retriever requires you to have `lark` package installed."
   ]
  },
  {
   "cell_type": "code",
   "id": "beec3e35-3750-408c-9f2a-d92cf0a9a321",
   "metadata": {},
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_core.documents import Document\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "docs = [\n",
    "    Document(\n",
    "        page_content=\"A bunch of scientists bring back dinosaurs and mayhem breaks loose\",\n",
    "        metadata={\"year\": 1993, \"rating\": 7.7, \"genre\": \"science fiction\"},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Leo DiCaprio gets lost in a dream within a dream within a dream within a ...\",\n",
    "        metadata={\"year\": 2010, \"director\": \"Christopher Nolan\", \"rating\": 8.2},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"A psychologist / detective gets lost in a series of dreams within dreams within dreams and Inception reused the idea\",\n",
    "        metadata={\"year\": 2006, \"director\": \"Satoshi Kon\", \"rating\": 8.6},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"A bunch of normal-sized women are supremely wholesome and some men pine after them\",\n",
    "        metadata={\"year\": 2019, \"director\": \"Greta Gerwig\", \"rating\": 8.3},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Toys come alive and have a blast doing so\",\n",
    "        metadata={\"year\": 1995, \"genre\": \"animated\"},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Three men walk into the Zone, three men walk out of the Zone\",\n",
    "        metadata={\n",
    "            \"year\": 1979,\n",
    "            \"director\": \"Andrei Tarkovsky\",\n",
    "            \"genre\": \"thriller\",\n",
    "            \"rating\": 9.9,\n",
    "        },\n",
    "    ),\n",
    "]\n",
    "vectorstore = Chroma.from_documents(docs, embedding_model)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "99771131-1efb-42e2-95f8-2aaa95f37677",
   "metadata": {},
   "source": [
    "### Creating our self-querying retriever\n",
    "\n",
    "Now we can instantiate our retriever. To do this we'll need to provide some information upfront about the metadata fields that our documents support and a short description of the document contents."
   ]
  },
  {
   "cell_type": "code",
   "id": "7832ca43-cc17-4375-bf4e-679b99584568",
   "metadata": {},
   "source": [
    "from langchain.chains.query_constructor.base import AttributeInfo\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "metadata_field_info = [\n",
    "    AttributeInfo(\n",
    "        name=\"genre\",\n",
    "        description=\"The genre of the movie. One of ['science fiction', 'comedy', 'drama', 'thriller', 'romance', 'action', 'animated']\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"year\",\n",
    "        description=\"The year the movie was released\",\n",
    "        type=\"integer\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"director\",\n",
    "        description=\"The name of the movie director\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"rating\", description=\"A 1-10 rating for the movie\", type=\"float\"\n",
    "    ),\n",
    "]\n",
    "document_content_description = \"Brief summary of a movie\"\n",
    "retriever = SelfQueryRetriever.from_llm(\n",
    "    llm,\n",
    "    vectorstore,\n",
    "    document_content_description,\n",
    "    metadata_field_info,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "9c66f4c8-3682-46ac-8f17-0839194888a3",
   "metadata": {},
   "source": [
    "### Testing it out\n",
    "\n",
    "And now we can actually try using our retriever!"
   ]
  },
  {
   "cell_type": "code",
   "id": "21c5df28-ea78-4f4e-99d6-489c864d1a04",
   "metadata": {},
   "source": [
    "# This example only specifies a filter\n",
    "retriever.invoke(\"I want to watch a movie rated higher than 8.5\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "228e5d70-d4cf-43bb-bc8e-3d6f11e784f2",
   "metadata": {},
   "source": [
    "# This example specifies a query and a filter\n",
    "retriever.invoke(\"Has Greta Gerwig directed any movies about women\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8244591e-97b5-4aba-b1e5-fe5e1996cb99",
   "metadata": {},
   "source": [
    "# This example specifies a composite filter\n",
    "retriever.invoke(\"What's a highly rated (above 8.5) science fiction film?\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "420a6906-66fb-449f-8626-2e399ae5e6a8",
   "metadata": {},
   "source": [
    "# This example specifies a query and composite filter\n",
    "retriever.invoke(\n",
    "    \"What's a movie after 1990 but before 2005 that's all about toys, and preferably is animated\"\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "4f25a751-f1d2-405e-84d6-fe9e4f60ce95",
   "metadata": {},
   "source": [
    "### Filter k\n",
    "\n",
    "We can also use the self query retriever to specify `k`: the number of documents to fetch.\n",
    "\n",
    "We can do this by passing `enable_limit=True` to the constructor."
   ]
  },
  {
   "cell_type": "code",
   "id": "ab56595f-0fb4-4b7f-8fc1-e85eff13255a",
   "metadata": {},
   "source": [
    "retriever = SelfQueryRetriever.from_llm(\n",
    "    llm,\n",
    "    vectorstore,\n",
    "    document_content_description,\n",
    "    metadata_field_info,\n",
    "    enable_limit=True,\n",
    ")\n",
    "\n",
    "# This example only specifies a relevant query\n",
    "retriever.invoke(\"What are two movies about dinosaurs\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "51e144c4-cbf4-4540-92e7-9a68e05f2480",
   "metadata": {},
   "source": [
    "## Constructing from scratch with LCEL\n",
    "\n",
    "To see what's going on under the hood, and to have more custom control, we can reconstruct our retriever from scratch.\n",
    "\n",
    "First, we need to create a query-construction chain. This chain will take a user query and generated a `StructuredQuery` object which captures the filters specified by the user. We provide some helper functions for creating a prompt and output parser. These have a number of tunable params that we'll ignore here for simplicity."
   ]
  },
  {
   "cell_type": "code",
   "id": "c5f501ac-46c1-4a54-9d23-c0530e8c88f0",
   "metadata": {},
   "source": [
    "from langchain.chains.query_constructor.base import (\n",
    "    StructuredQueryOutputParser,\n",
    "    get_query_constructor_prompt,\n",
    ")\n",
    "\n",
    "prompt = get_query_constructor_prompt(\n",
    "    document_content_description,\n",
    "    metadata_field_info,\n",
    ")\n",
    "output_parser = StructuredQueryOutputParser.from_components()\n",
    "query_constructor = prompt | llm | output_parser"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "8deb5d44-632f-4f41-b139-fc811979e6e8",
   "metadata": {},
   "source": [
    "Let's look at our prompt:"
   ]
  },
  {
   "cell_type": "code",
   "id": "eed553cb-8575-486b-8349-0806b7817a8c",
   "metadata": {},
   "source": [
    "print(prompt.format(query=\"dummy question\"))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "00420512-c395-4661-8d07-c7f6f1b45793",
   "metadata": {},
   "source": [
    "And what our full chain produces:"
   ]
  },
  {
   "cell_type": "code",
   "id": "139cce01-ca75-452b-8de2-033ceec27158",
   "metadata": {},
   "source": [
    "query_constructor.invoke(\n",
    "    {\n",
    "        \"query\": \"What are some sci-fi movies from the 90's directed by Luc Besson about taxi drivers\"\n",
    "    }\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "9582a5fa-ffed-4d50-ad74-9b12d7d94b2a",
   "metadata": {},
   "source": "The query constructor is the key element of the self-query retriever. To make a great retrieval system you'll need to make sure your query constructor works well. Often this requires adjusting the prompt, the examples in the prompt, the attribute descriptions, etc. For an example that walks through refining a query constructor on some hotel inventory data, [check out this cookbook](https://github.com/langchain-ai/langchain/blob/master/cookbook/self_query_hotel_search.ipynb)."
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Structured query translator\n",
    "\n",
    "The next key element is the structured query translator. This is the object responsible for translating the generic `StructuredQuery` object into a metadata filter in the syntax of the vector store you're using. LangChain comes with a number of built-in translators. To see them all head to the [Integrations section](/docs/integrations/retrievers/self_query).\n"
   ],
   "id": "e815d594ce2520a1"
  },
  {
   "cell_type": "code",
   "id": "05f07ead-9aac-4079-9dde-784cb7aa1a8a",
   "metadata": {},
   "source": [
    "from langchain_community.query_constructors.chroma import ChromaTranslator\n",
    "\n",
    "retriever = SelfQueryRetriever(\n",
    "    query_constructor=query_constructor,\n",
    "    vectorstore=vectorstore,\n",
    "    structured_query_translator=ChromaTranslator(),\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "0ee155c9-7b02-4fe9-8de3-e37385c465af",
   "metadata": {},
   "source": [
    "retriever.invoke(\n",
    "    \"What's a movie after 1990 but before 2005 that's all about toys, and preferably is animated\"\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
