{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d3d2fbcbe55ee7e",
   "metadata": {},
   "source": [
    "# 1. OpenAI Basics\n",
    "<br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d729f02cd6985c",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "### Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "%pip install python-dotenv~=1.0 docarray~=0.40.0 pydantic~=2.9 pypdf~=5.1 --upgrade --quiet\n",
    "%pip install openai~=1.54 --upgrade --quiet\n",
    "\n",
    "# If running locally, you can do this instead:\n",
    "#%pip install -r ../requirements.txt"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c4e345ac5e559caa",
   "metadata": {},
   "source": "### Load environment variables"
  },
  {
   "cell_type": "code",
   "id": "2e898b3991430510",
   "metadata": {},
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "# If running in Google Colab, you can use this code instead:\n",
    "# import os\n",
    "# from google.colab import userdata\n",
    "# os.environ[\"AZURE_OPENAI_API_KEY\"] = userdata.get(\"AZURE_OPENAI_API_KEY\")\n",
    "# os.environ[\"AZURE_OPENAI_ENDPOINT\"] = userdata.get(\"AZURE_OPENAI_ENDPOINT\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "710b734640645f93",
   "metadata": {},
   "source": [
    "## Chat\n",
    "\n",
    "### Setup OpenAI client and helper function"
   ]
  },
  {
   "cell_type": "code",
   "id": "fe76ff681fdc6970",
   "metadata": {},
   "source": [
    "from openai import AzureOpenAI\n",
    "\n",
    "# Create an OpenAI client, connecting to OpenAI via an Azure deployment \n",
    "client = AzureOpenAI(api_version=\"2024-10-01-preview\")\n",
    "\n",
    "# These models (deployments) are currently available: gpt-4o, gpt-4o-mini, o1-mini, o1-preview  \n",
    "def get_completion(prompt: str=None, model: str = \"gpt-4o\", messages: list = None, useJson: bool = False) -> str:\n",
    "    if messages is None:\n",
    "        messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        # stop=[\"Paris\"], # stop the completion when the model generates the word \"Paris\"\n",
    "        # max_tokens=100, # maximum number of tokens to generate\n",
    "        temperature=1.0, # 0.0: deterministic, 1.0: more creative\n",
    "        response_format={ \"type\": \"json_object\" } if useJson else { \"type\": \"text\" },\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "4c379396314be880",
   "metadata": {},
   "source": [
    "### Try some basic chatting with the model"
   ]
  },
  {
   "cell_type": "code",
   "id": "19e7fb0da1babd81",
   "metadata": {},
   "source": [
    "question = \"What is the capital of France?\"\n",
    "# Here we use a kind of prompt template for the user's question (can be useful sometimes)\n",
    "prompt = f\"\"\"\n",
    "Be very funny when answering the questions below. \n",
    "\n",
    "Question from user, separated by ```:  \n",
    "```{question}```\n",
    "\"\"\"\n",
    "response = get_completion(prompt) #, model=\"o1-preview\")\n",
    "print(response)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "32166c9d82a10423",
   "metadata": {},
   "source": [
    "### Let's use a system message to set the tone"
   ]
  },
  {
   "cell_type": "code",
   "id": "afd0a16317bac2e9",
   "metadata": {},
   "source": [
    "messages = [\n",
    "    # Set the tone of the conversation, using system instructions: \n",
    "    {\"role\": \"system\", \"content\": \"You are Marvin, the depressed robot from Hitchhiker's Guide to the Galaxy.\"},\n",
    "    {\"role\": \"user\", \"content\": prompt},\n",
    "]\n",
    "\n",
    "response = get_completion(messages=messages) #, model=\"o1-preview\")\n",
    "print(response)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "8dd74b8c0b35f911",
   "metadata": {},
   "source": [
    "### Include some assistant messages, as an example of setting up a conversation history"
   ]
  },
  {
   "cell_type": "code",
   "id": "2cfe1b53011697b6",
   "metadata": {},
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are Marvin, the depressed robot from Hitchhiker's Guide to the Galaxy. You absolutely hate jokes and refuse to play along and instead change the subject.\"},\n",
    "    {\"role\": \"user\", \"content\": \"knock knock.\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Who's there?\"},\n",
    "    {\"role\": \"user\", \"content\": \"A little old lady.\"}\n",
    "]\n",
    "\n",
    "response = get_completion(messages=messages) #, model=\"o1-preview\")\n",
    "print(response)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "6dc49da8be29536f",
   "metadata": {},
   "source": [
    "### Let's try some JSON output"
   ]
  },
  {
   "cell_type": "code",
   "id": "7c68103f39311bb8",
   "metadata": {},
   "source": [
    "question = \"Tell me a joke about Iceland.\"\n",
    "prompt = f\"\"\"\n",
    "Be very funny when answering the questions below. \n",
    "\n",
    "Question from user, separated by ```:  \n",
    "```{question}```\n",
    "\"\"\"\n",
    "response = get_completion(prompt, useJson=True) #, model=\"o1-preview\")\n",
    "print(response)\n",
    "\n",
    "# NOTE: If you get an error, add this text to the prompt: \n",
    "# \"Return the response in JSON format.\""
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
