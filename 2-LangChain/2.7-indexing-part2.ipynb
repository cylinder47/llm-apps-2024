{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df9c63ee419172cd",
   "metadata": {},
   "source": [
    "# 2.3 Vectorstores and Embeddings - part 2\n",
    "\n",
    "## Using other embedding models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5473e30123fde2",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "### Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "519de3d821771d7a",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "ragatouille 0.0.8.post4 requires sentence-transformers<3.0.0,>=2.2.2, but you have sentence-transformers 3.3.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install python-dotenv~=1.0 docarray~=0.40.0 pypdf~=5.1 --upgrade --quiet\n",
    "%pip install chromadb~=0.5.18 sentence-transformers~=3.3 --upgrade --quiet \n",
    "%pip install langchain~=0.3.7 langchain_openai~=0.2.6 langchain_community~=0.3.5 langchain-huggingface~=0.1.2 --upgrade --quiet\n",
    "%pip install unstructured[md]~=0.16.5 --upgrade --quiet\n",
    "\n",
    "# If running locally, you can do this instead:\n",
    "#%pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad9edd014eabb82",
   "metadata": {},
   "source": [
    "### Load environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57d1c3a5b3825906",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "# If running in Google Colab, you can use this code instead:\n",
    "# from google.colab import userdata\n",
    "# os.environ[\"AZURE_OPENAI_API_KEY\"] = userdata.get(\"AZURE_OPENAI_API_KEY\")\n",
    "# os.environ[\"AZURE_OPENAI_ENDPOINT\"] = userdata.get(\"AZURE_OPENAI_ENDPOINT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1242a28ea25bed86",
   "metadata": {},
   "source": [
    "### Setup Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "370e09d08dd84395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension in OpenAI embedding model: 3072\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import AzureChatOpenAI, AzureOpenAIEmbeddings\n",
    "api_version = \"2024-10-01-preview\"\n",
    "oai_embedding_model = AzureOpenAIEmbeddings(model=\"text-embedding-3-large\", openai_api_version=api_version)\n",
    "print(f\"Dimension in OpenAI embedding model: {len(oai_embedding_model.embed_query('test'))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff9c7d49294ee16",
   "metadata": {},
   "source": [
    "### Setup path to data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e82aaefb3945dd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../data\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32c9375e2a53521",
   "metadata": {},
   "source": [
    "## Setup HuggingFace Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "836bb4ae8a12e1d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4781fbdef656475da010193e03d18df2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee07a13b337245e0b7b1884a9ad8d660",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/208 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "497a14a75d5b43929cf2638dd73dd57d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/600k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1353257ace44425a3bdb036b4ed92d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/55.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb41454c8d9047ad9058bd83c00b00d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/833 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddf12aad0eec4e088c3a397016ff17a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78a3af1c543d425894a44870cb4afb08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.63k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bb7595242e54de1bb4392040c76dee9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/2.78M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c8aaf5f40cd4338866598b366d25471",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/1.67M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "700f724863cd4a529da739aa768c33fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/7.03M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e1cb8244553466c890178c4ae88bca6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/80.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73e47335d940464e987a120b9aeac56f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/370 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b464e04e302d4a60a4342f90c3244778",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/296 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension in HF model: 896\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.embeddings import Embeddings\n",
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# Try using an open-source embedding function from HuggingFace\n",
    "\n",
    "# See https://huggingface.co/spaces/mteb/leaderboard\n",
    "hf_embedding_model: Embeddings = HuggingFaceEmbeddings(\n",
    "    #model_name=\"avsolatorio/GIST-all-MiniLM-L6-v2\" # 23M params, 0.08GB mem use, 384 dim, 512 tokens, 59 avg score\n",
    "    #model_name=\"intfloat/multilingual-e5-large-instruct\" # 560M params, 2.09GB mem use, 1024 dim, 514 tokens, 63.61 avg score\n",
    "    model_name=\"HIT-TMG/KaLM-embedding-multilingual-mini-instruct-v1\" # 494M params, 1.84GB mem use, 896 dim, 131k tokens, 64.74 avg score\n",
    "    #model_name=\"Salesforce/SFR-Embedding-2_R\" # 7B params, 26GB mem use, 4096 dim, 32k tokens, 70.32 avg score\n",
    "    #model_name=\"nvidia/NV-Embed-v2\" # 7B params, 29GB mem use, 4096 dim, 32k tokens, 72.31 avg score\n",
    ")\n",
    "print(f\"Dimension in HF model: {len(hf_embedding_model.embed_query('test'))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed362d9e80bf17f",
   "metadata": {},
   "source": [
    "### Load the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f111c2cfbaffda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import UnstructuredMarkdownLoader\n",
    "\n",
    "loaders = [\n",
    "    UnstructuredMarkdownLoader(f\"{data_path}/listing1.md\"),\n",
    "    UnstructuredMarkdownLoader(f\"{data_path}/listing2.md\"),\n",
    "    UnstructuredMarkdownLoader(f\"{data_path}/listing3.md\"),\n",
    "]\n",
    "documents = []\n",
    "for loader in loaders:\n",
    "    documents.extend(loader.load())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41cb18bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': '../data/listing1.md'}, page_content=\"Luxurious 2-Bedroom Apartment in Downtown Vista Verde\\n\\nPrice: $450,000 Property Type: Apartment Year Built: 2018 Square Footage: 1,200 sqft Bedrooms: 2 Bathrooms: 2 Parking: 1 dedicated parking spot in underground garage HOA Fees: $300/month Location: 1200 Grand Avenue, Downtown Vista Verde\\n\\nOverview\\n\\nExperience the epitome of urban living in this meticulously designed 2-bedroom apartment located in the heart of Downtown Vista Verde. Boasting a spacious 1,200 square feet of modern living space, this apartment offers a seamless blend of luxury, comfort, and convenience. With its prime location, you're just steps away from the city's finest dining, shopping, and entertainment options. The building's amenities include a state-of-the-art fitness center, a rooftop terrace with panoramic city views, and a private underground parking garage.\\n\\nLiving Room\\n\\nThe expansive living room serves as the heart of the apartment, featuring floor-to-ceiling windows that flood the space with natural light and offer stunning cityscape views. The open-concept design allows for a variety of furniture arrangements, perfect for entertaining guests or enjoying a quiet evening at home.\\n\\nKitchen\\n\\nThe gourmet kitchen is a chef's dream, equipped with high-end stainless steel appliances, quartz countertops, and custom cabinetry. The large center island provides ample space for meal preparation and casual dining.\\n\\nBedrooms\\n\\nThe master bedroom is a tranquil retreat, offering generous closet space and an en-suite bathroom with dual vanities, a walk-in shower, and a soaking tub. The second bedroom is equally spacious, with easy access to the second full bathroom, making it ideal for guests or as a home office.\\n\\nAdditional Features\\n\\nHardwood flooring throughout the living areas and bedrooms\\n\\nIn-unit laundry with washer and dryer\\n\\nSmart home technology including a programmable thermostat and keyless entry\\n\\nDedicated storage unit in the basement\\n\\nFinancials and Metrics\\n\\nAsking Price: $450,000\\n\\nPrice per Square Foot: $375\\n\\nEstimated Monthly Mortgage: $2,100 (assuming 20% down on a 30-year mortgage at 3.5% interest rate)\\n\\nHOA Fees: $300/month (includes water, trash, maintenance of common areas, and access to building amenities)\\n\\nFor more information or to schedule a viewing, please contact Vista Verde Realty at (555) 123-4567 or email sales@vistaverderealty.com.\"),\n",
       " Document(metadata={'source': '../data/listing2.md'}, page_content=\"Contemporary 1-Bedroom Loft in The Artisan District\\n\\nPrice: $325,000 Property Type: Apartment Year Built: 2019 Square Footage: 950 sqft Bedrooms: 1 Bathrooms: 1.5 Parking: On-street parking with city permit HOA Fees: $250/month Location: 408 Creativity Lane, The Artisan District\\n\\nOverview\\n\\nStep into the modern era with this sleek, contemporary 1-bedroom loft situated in the vibrant heart of The Artisan District. Spanning 950 square feet, this apartment combines the industrial chic of loft living with modern amenities and finishes. It's an ideal space for those who appreciate design, with the district's galleries, studios, and boutiques right at your doorstep. The complex itself is a testament to modern architecture and offers residents a communal rooftop deck and a high-tech fitness center.\\n\\nLiving Room\\n\\nThe living area is defined by its open space, high ceilings, and industrial-sized windows that invite an abundance of natural light. The polished concrete floors and exposed ductwork add to the loft's urban appeal, creating a versatile space that can easily adapt to your aesthetic and functional needs.\\n\\nKitchen\\n\\nThe kitchen is a modern culinary space, outfitted with stainless steel appliances, quartz countertops, and sleek, minimalist cabinetry. The layout is open to the living area, making it perfect for entertaining or enjoying a casual meal at the breakfast bar.\\n\\nBedroom\\n\\nThe bedroom area is strategically placed to maximize privacy while maintaining the loft's open concept. It features ample closet space and an adjacent modern bathroom with a walk-in shower and contemporary fixtures. A half-bath near the living area provides added convenience for guests.\\n\\nAdditional Features\\n\\nIn-unit laundry closet with stackable washer and dryer\\n\\nCentral heating and cooling systems controlled via smart home technology\\n\\nExclusive access to the building's rooftop deck with panoramic city views\\n\\nA secure, keyless entry system and video intercom for guest access\\n\\nFinancials and Metrics\\n\\nAsking Price: $325,000\\n\\nPrice per Square Foot: $342\\n\\nEstimated Monthly Mortgage: $1,520 (assuming 20% down on a 30-year mortgage at 3.5% interest rate)\\n\\nHOA Fees: $250/month (includes exterior maintenance, access to amenities, and trash removal)\\n\\nFor more details or to schedule a visit, please contact Artisan District Homes at (555) 234-5678 or send an email to contact@artisandistricthomes.com.\"),\n",
       " Document(metadata={'source': '../data/listing3.md'}, page_content=\"2022 Tesla Model S Plaid - A Marvel of Electric Performance\\n\\nPrice: $129,900 Make: Tesla Model: Model S Plaid Year: 2022 Mileage: 5,000 miles Exterior Color: Midnight Silver Metallic Interior Color: Black with Carbon Fiber Decor Engine: Triple Electric Motor AWD Battery Range: Up to 396 miles on a single charge Charging: Supercharger capable, includes home charging kit\\n\\nOverview\\n\\nExperience the pinnacle of electric performance with the 2022 Tesla Model S Plaid. This vehicle not only redefines what an electric car can be, but it also sets a new standard for luxury sedans. With just 5,000 miles on the odometer, it's as close to new as you can get without driving it off the showroom floor. The Model S Plaid's breathtaking acceleration, unparalleled range, and advanced technology make it a standout in the electric vehicle market.\\n\\nPerformance\\n\\n0 to 60 mph in 1.99 seconds thanks to its tri-motor all-wheel drive powertrain.\\n\\nTop speed of 200 mph and a quarter mile in just 9.23 seconds.\\n\\nCarbon-sleeved rotors and Torque Vectoring provide exceptional handling and stability.\\n\\nExterior Features\\n\\nThe Midnight Silver Metallic exterior is complemented by 21-inch Arachnid wheels, providing a sleek and aggressive stance. The all-glass roof offers beautiful, expansive views while adding to the car's aerodynamic design. Automatic door handles auto-present upon approach and retract when in motion, enhancing the vehicle's smooth lines.\\n\\nInterior Comfort and Technology\\n\\nThe black interior features carbon fiber decor and premium multi-zone climate control for maximum comfort. A 17-inch cinematic display controls most of the car's functions, offering both entertainment and utility with an ultra-responsive touch screen. The Plaid's interior also includes: - Autopilot with full self-driving capability for future activation - Premium sound system with 22 speakers and active noise canceling - HEPA air filtration system to ensure the cabin air is clean and fresh\\n\\nSafety\\n\\nTesla's safety is unparalleled, with a low center of gravity, rigid body structure, and large crumple zones. The Model S Plaid includes: - Autopilot as standard, with automatic emergency braking, lane keeping assist, and adaptive cruise control. - Eight surround cameras provide 360 degrees of visibility. - Twelve ultrasonic sensors for detecting nearby cars and preventing potential collisions.\\n\\nFinancials and Metrics\\n\\nAsking Price: $129,900\\n\\nEstimated Monthly Payment: $2,000 (assuming 20% down on a 60-month loan at 2.49% APR)\\n\\nWarranty: 4-year vehicle warranty, 8-year battery and powertrain warranty still in effect\\n\\nFor a test drive or more information, contact Electric Auto Gallery at (555) 321-9876 or visit our website to view this vehicle and more at electricautogallery.com.\")]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f275e520151578e",
   "metadata": {},
   "source": [
    "### Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb6b3c375ec5a4aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "splitDocs count: 9\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "# split it into chunks\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=32)\n",
    "splitDocs = text_splitter.split_documents(documents)\n",
    "\n",
    "# embeddings = []\n",
    "# for sp in splitDocs:\n",
    "#     embeddings = embedding.embed_query(sp.page_content)\n",
    "\n",
    "print(f\"splitDocs count: {len(splitDocs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0d031b48d95b3",
   "metadata": {},
   "source": [
    "### Setup vector stores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5bcd4404972ec34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the vector store(s)...\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "print('Loading the vector store(s)...')\n",
    "oai_vectorstore = Chroma.from_documents(collection_name=\"listings_oai\", documents=splitDocs, embedding=oai_embedding_model)\n",
    "hf_vectorstore = Chroma.from_documents(collection_name=\"listings_hf\", documents=splitDocs, embedding=hf_embedding_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8b7bf18bd2a56f",
   "metadata": {},
   "source": [
    "### Query time (similarity search)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b0d68c12e64b92c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity search...\n",
      "Result: 1\n",
      "{'source': '../data/listing1.md'}\n",
      "Content: \n",
      "\"Luxurious 2-Bedroom Apartment in Downtown Vista Verde\n",
      "\n",
      "Price: $450,000 Property Type: Apartment Year Built: 2018 Square Footage: 1,200 sqft Bedrooms: 2 Bathrooms: 2 Parking: 1 dedicated parking spot in underground garage HOA Fees: $300/month Location: 1200 Grand Avenue, Downtown Vista Verde\n",
      "\n",
      "Overview\n",
      "\n",
      "Experience the epitome of urban living in this meticulously designed 2-bedroom apartment located in the heart of Downtown Vista Verde. Boasting a spacious 1,200 square feet of modern living space, this apartment offers a seamless blend of luxury, comfort, and convenience. With its prime location, you're just steps away from the city's finest dining, shopping, and entertainment options. The building's amenities include a state-of-the-art fitness center, a rooftop terrace with panoramic city views, and a private underground parking garage.\n",
      "\n",
      "Living Room\"\n"
     ]
    }
   ],
   "source": [
    "question = \"I'm looking for a 2-bedroom apartment\"\n",
    "#question = \"I'm looking for an apartment with a laundry closet and preferably a stackable washer and dryer.\"\n",
    "#question = \"I'm looking for an electric car with autopilot\"\n",
    "# TODO: Write your own questions\n",
    "\n",
    "print(\"Similarity search...\")\n",
    "# Compare results from different embeddings\n",
    "#docs = oai_vectorstore.similarity_search(question, k=1)\n",
    "docs = hf_vectorstore.similarity_search(question, k=1)\n",
    "\n",
    "length = len(docs)\n",
    "print(f\"Result: {length}\")\n",
    "\n",
    "for d in docs:\n",
    "    print(d.metadata)\n",
    "    print(f'Content: \\n\"{d.page_content}\"')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fd2954",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
