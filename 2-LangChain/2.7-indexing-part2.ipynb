{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 2.3 Vectorstores and Embeddings - part 2\n",
    "\n",
    "## Using other embedding models"
   ],
   "id": "df9c63ee419172cd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Setup\n",
    "\n",
    "### Install dependencies"
   ],
   "id": "8b5473e30123fde2"
  },
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "code",
   "source": [
    "%pip install python-dotenv~=1.0 docarray~=0.40.0 pypdf~=5.1 --upgrade --quiet\n",
    "%pip install chromadb~=0.5.18 sentence-transformers~=3.3 --upgrade --quiet \n",
    "%pip install langchain~=0.3.7 langchain_openai~=0.2.6 langchain_community~=0.3.5 langchain-huggingface~=0.1.2 --upgrade --quiet\n",
    "%pip install unstructured[md]~=0.16.5 --upgrade --quiet\n",
    "\n",
    "# If running locally, you can do this instead:\n",
    "#%pip install -r ../requirements.txt"
   ],
   "id": "519de3d821771d7a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Load environment variables",
   "id": "8ad9edd014eabb82"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "# If running in Google Colab, you can use this code instead:\n",
    "# from google.colab import userdata\n",
    "# os.environ[\"AZURE_OPENAI_API_KEY\"] = userdata.get(\"AZURE_OPENAI_API_KEY\")\n",
    "# os.environ[\"AZURE_OPENAI_ENDPOINT\"] = userdata.get(\"AZURE_OPENAI_ENDPOINT\")"
   ],
   "id": "57d1c3a5b3825906",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Setup Models",
   "id": "1242a28ea25bed86"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain_openai import AzureChatOpenAI, AzureOpenAIEmbeddings\n",
    "api_version = \"2024-10-01-preview\"\n",
    "oai_embedding_model = AzureOpenAIEmbeddings(model=\"text-embedding-3-large\", openai_api_version=api_version)\n",
    "print(f\"Dimension in OpenAI embedding model: {len(oai_embedding_model.embed_query('test'))}\")"
   ],
   "id": "370e09d08dd84395",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Setup path to data ",
   "id": "aff9c7d49294ee16"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "data_path = \"../data\"",
   "id": "e82aaefb3945dd97"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Setup HuggingFace Embedding Model",
   "id": "c32c9375e2a53521"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain_core.embeddings import Embeddings\n",
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# Try using an open-source embedding function from HuggingFace\n",
    "\n",
    "# See https://huggingface.co/spaces/mteb/leaderboard\n",
    "hf_embedding_model: Embeddings = HuggingFaceEmbeddings(\n",
    "    #model_name=\"avsolatorio/GIST-all-MiniLM-L6-v2\" # 23M params, 0.08GB mem use, 384 dim, 512 tokens, 59 avg score\n",
    "    #model_name=\"intfloat/multilingual-e5-large-instruct\" # 560M params, 2.09GB mem use, 1024 dim, 514 tokens, 63.61 avg score\n",
    "    model_name=\"HIT-TMG/KaLM-embedding-multilingual-mini-instruct-v1\" # 494M params, 1.84GB mem use, 896 dim, 131k tokens, 64.74 avg score\n",
    "    #model_name=\"Salesforce/SFR-Embedding-2_R\" # 7B params, 26GB mem use, 4096 dim, 32k tokens, 70.32 avg score\n",
    "    #model_name=\"nvidia/NV-Embed-v2\" # 7B params, 29GB mem use, 4096 dim, 32k tokens, 72.31 avg score\n",
    ")\n",
    "print(f\"Dimension in HF model: {len(hf_embedding_model.embed_query('test'))}\")"
   ],
   "id": "836bb4ae8a12e1d3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Load the documents",
   "id": "9ed362d9e80bf17f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain_community.document_loaders import UnstructuredMarkdownLoader\n",
    "\n",
    "loaders = [\n",
    "    UnstructuredMarkdownLoader(f\"{data_path}/listing1.md\"),\n",
    "    UnstructuredMarkdownLoader(f\"{data_path}/listing2.md\"),\n",
    "    UnstructuredMarkdownLoader(f\"{data_path}/listing3.md\"),\n",
    "]\n",
    "documents = []\n",
    "for loader in loaders:\n",
    "    documents.extend(loader.load())\n"
   ],
   "id": "1f111c2cfbaffda0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Split",
   "id": "4f275e520151578e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "# split it into chunks\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=32)\n",
    "splitDocs = text_splitter.split_documents(documents)\n",
    "\n",
    "# embeddings = []\n",
    "# for sp in splitDocs:\n",
    "#     embeddings = embedding.embed_query(sp.page_content)\n",
    "\n",
    "print(f\"splitDocs count: {len(splitDocs)}\")"
   ],
   "id": "fb6b3c375ec5a4aa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Setup vector stores",
   "id": "bf0d031b48d95b3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "print('Loading the vector store(s)...')\n",
    "oai_vectorstore = Chroma.from_documents(collection_name=\"listings_oai\", documents=splitDocs, embedding=oai_embedding_model)\n",
    "hf_vectorstore = Chroma.from_documents(collection_name=\"listings_hf\", documents=splitDocs, embedding=hf_embedding_model)"
   ],
   "id": "a5bcd4404972ec34",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Query time (similarity search)!",
   "id": "5d8b7bf18bd2a56f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "question = \"I'm looking for a 2-bedroom apartment\"\n",
    "#question = \"I'm looking for an apartment with a laundry closet and preferably a stackable washer and dryer.\"\n",
    "#question = \"I'm looking for an electric car with autopilot\"\n",
    "# TODO: Write your own questions\n",
    "\n",
    "print(\"Similarity search...\")\n",
    "# Compare results from different embeddings\n",
    "#docs = oai_vectorstore.similarity_search(question, k=1)\n",
    "docs = hf_vectorstore.similarity_search(question, k=1)\n",
    "\n",
    "length = len(docs)\n",
    "print(f\"Result: {length}\")\n",
    "\n",
    "for d in docs:\n",
    "    print(d.metadata)\n",
    "    print(f'Content: \\n\"{d.page_content}\"')\n",
    "    \n",
    "    "
   ],
   "id": "7b0d68c12e64b92c",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
