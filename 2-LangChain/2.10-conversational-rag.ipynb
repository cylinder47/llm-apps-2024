{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "943ea36a1082641e",
   "metadata": {},
   "source": [
    "# 2.6 Conversational RAG - Adding chat history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9dd64db952da1d",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "### Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e800faf4e660819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install python-dotenv~=1.0 docarray~=0.40.0 pypdf~=5.1 --upgrade --quiet\n",
    "%pip install chromadb~=0.5.18 sentence-transformers~=3.3 --upgrade --quiet \n",
    "%pip install langchain~=0.3.7 langchain_openai~=0.2.6 langchain_community~=0.3.5 --upgrade --quiet\n",
    "\n",
    "# If running locally, you can do this instead:\n",
    "#%pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23db6d4042f86418",
   "metadata": {},
   "source": [
    "### Load environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9f00cf70a4e8556",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "# If running in Google Colab, you can use this code instead:\n",
    "# from google.colab import userdata\n",
    "# os.environ[\"AZURE_OPENAI_API_KEY\"] = userdata.get(\"AZURE_OPENAI_API_KEY\")\n",
    "# os.environ[\"AZURE_OPENAI_ENDPOINT\"] = userdata.get(\"AZURE_OPENAI_ENDPOINT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3d11e1151a7e80",
   "metadata": {},
   "source": [
    "### Setup models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba095904eb63506",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureChatOpenAI, AzureOpenAIEmbeddings\n",
    "api_version = \"2024-10-01-preview\"\n",
    "llm = AzureChatOpenAI(deployment_name=\"gpt-4o\", temperature=0.0, openai_api_version=api_version)\n",
    "embedding_model = AzureOpenAIEmbeddings(model=\"text-embedding-3-large\", openai_api_version=api_version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0dcb326c5b015b",
   "metadata": {},
   "source": [
    "### Setup LangSmith tracing for this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3b906942dc243b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# API key etc is in the .env file\n",
    "# my_name = \"Totoro\"\n",
    "# os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "# os.environ[\"LANGCHAIN_PROJECT\"] = f\"tokyo24-test-{my_name}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979a99375d945ac8",
   "metadata": {},
   "source": [
    "### Setup path to data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "438411075ed796ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../data\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bde3aec39acd7df",
   "metadata": {},
   "source": [
    "## Initialize VectorDB - like before"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3bd1965176d16fc",
   "metadata": {},
   "source": [
    "Let's load our vectorDB and set it up like in previous chapters. _If you already have a persisted vectorDB, you can skip to \"Vector DB\" below._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1bfd8e7e18c145ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD DOCS\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "# Load PDFs\n",
    "loaders = [\n",
    "    PyPDFLoader(f\"{data_path}/MachineLearning-Lecture01.pdf\"),\n",
    "    PyPDFLoader(f\"{data_path}/MachineLearning-Lecture01.pdf\"),\n",
    "    PyPDFLoader(f\"{data_path}/MachineLearning-Lecture03.pdf\")\n",
    "]\n",
    "docs = []\n",
    "for loader in loaders:\n",
    "    docs.extend(loader.load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2e7b06813bc6b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPLIT DOCS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 1500,\n",
    "    chunk_overlap = 150\n",
    ")\n",
    "splits = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "522653aabd8bc7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vector DB - Indexing / Store\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "# Optional persist_directory to save the database\n",
    "persist_directory = './db/chroma-ML-docs/'\n",
    "\n",
    "vectordb = Chroma.from_documents(\n",
    "    collection_name=\"ml_docs\",\n",
    "    documents=splits,\n",
    "    embedding=embedding_model,\n",
    "    persist_directory=persist_directory # Optionally persist the database\n",
    ")\n",
    "retriever = vectordb.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58985b34dd50ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "322\n"
     ]
    }
   ],
   "source": [
    "print(vectordb._collection.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdafbc5f8a2ae265",
   "metadata": {},
   "source": [
    "## Create a RAG chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9586e5c7b990ae0e",
   "metadata": {},
   "source": [
    "### Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "648cec5d45827242",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "# Build prompt\n",
    "q_and_a_system_template = \"\"\"Use the following pieces of context to answer the question. If you don't know the answer, just say that you don't know, don't try to make up an answer. Use three sentences maximum. Keep the answer as concise as possible. \n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\"\"\"\n",
    "q_and_a_prompt = ChatPromptTemplate([\n",
    "    (\"system\", q_and_a_system_template),\n",
    "    (\"human\", \"{input}\"),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e318f24122264f82",
   "metadata": {},
   "source": [
    "### Start with a simple RAG chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8eb4278965d02e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "combine_docs_chain = create_stuff_documents_chain(llm, q_and_a_prompt)\n",
    "rag_chain = create_retrieval_chain(retriever, combine_docs_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "74eedc34d62f9252",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Is probability a class topic?\"\n",
    "result = rag_chain.invoke({\"input\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "826006c239d636de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'Is probability a class topic?',\n",
       " 'context': [Document(metadata={'page': 4, 'source': '../data/MachineLearning-Lecture01.pdf'}, page_content=\"of this class will not be very programming intensive, although we will do some \\nprogramming, mostly in either MATLAB or Octave. I'll say a bit more about that later.  \\nI also assume familiarity with basic probability and statistics. So most undergraduate \\nstatistics class, like Stat 116 taught here at Stanford, will be more than enough. I'm gonna \\nassume all of you know what random variables are, that all of you know what expectation \\nis, what a variance or a random variable is. And in case of some of you, it's been a while \\nsince you've seen some of this material. At some of the discussion sections, we'll actually \\ngo over some of the prerequisites, sort of as a refresher course under prerequisite class. \\nI'll say a bit more about that later as well.  \\nLastly, I also assume familiarity with basic linear algebra. And again, most undergraduate \\nlinear algebra courses are more than enough. So if you've taken courses like Math 51, \\n103, Math 113 or CS205 at Stanford, that would be more than enough. Basically, I'm \\ngonna assume that all of you know what matrixes and vectors are, that you know how to \\nmultiply matrices and vectors and multiply matrix and matrices, that you know what a \\nmatrix inverse is. If you know what an eigenvector of a matrix is, that'd be even better. \\nBut if you don't quite know or if you're not quite sure, that's fine, too. We'll go over it in \\nthe review sections.\"),\n",
       "  Document(metadata={'page': 4, 'source': '../data/MachineLearning-Lecture01.pdf'}, page_content=\"of this class will not be very programming intensive, although we will do some \\nprogramming, mostly in either MATLAB or Octave. I'll say a bit more about that later.  \\nI also assume familiarity with basic probability and statistics. So most undergraduate \\nstatistics class, like Stat 116 taught here at Stanford, will be more than enough. I'm gonna \\nassume all of you know what random variables are, that all of you know what expectation \\nis, what a variance or a random variable is. And in case of some of you, it's been a while \\nsince you've seen some of this material. At some of the discussion sections, we'll actually \\ngo over some of the prerequisites, sort of as a refresher course under prerequisite class. \\nI'll say a bit more about that later as well.  \\nLastly, I also assume familiarity with basic linear algebra. And again, most undergraduate \\nlinear algebra courses are more than enough. So if you've taken courses like Math 51, \\n103, Math 113 or CS205 at Stanford, that would be more than enough. Basically, I'm \\ngonna assume that all of you know what matrixes and vectors are, that you know how to \\nmultiply matrices and vectors and multiply matrix and matrices, that you know what a \\nmatrix inverse is. If you know what an eigenvector of a matrix is, that'd be even better. \\nBut if you don't quite know or if you're not quite sure, that's fine, too. We'll go over it in \\nthe review sections.\"),\n",
       "  Document(metadata={'page': 4, 'source': '../data/MachineLearning-Lecture01.pdf'}, page_content=\"of this class will not be very programming intensive, although we will do some \\nprogramming, mostly in either MATLAB or Octave. I'll say a bit more about that later.  \\nI also assume familiarity with basic probability and statistics. So most undergraduate \\nstatistics class, like Stat 116 taught here at Stanford, will be more than enough. I'm gonna \\nassume all of you know what random variables are, that all of you know what expectation \\nis, what a variance or a random variable is. And in case of some of you, it's been a while \\nsince you've seen some of this material. At some of the discussion sections, we'll actually \\ngo over some of the prerequisites, sort of as a refresher course under prerequisite class. \\nI'll say a bit more about that later as well.  \\nLastly, I also assume familiarity with basic linear algebra. And again, most undergraduate \\nlinear algebra courses are more than enough. So if you've taken courses like Math 51, \\n103, Math 113 or CS205 at Stanford, that would be more than enough. Basically, I'm \\ngonna assume that all of you know what matrixes and vectors are, that you know how to \\nmultiply matrices and vectors and multiply matrix and matrices, that you know what a \\nmatrix inverse is. If you know what an eigenvector of a matrix is, that'd be even better. \\nBut if you don't quite know or if you're not quite sure, that's fine, too. We'll go over it in \\nthe review sections.\"),\n",
       "  Document(metadata={'page': 4, 'source': '../data/MachineLearning-Lecture01.pdf'}, page_content=\"of this class will not be very programming intensive, although we will do some \\nprogramming, mostly in either MATLAB or Octave. I'll say a bit more about that later.  \\nI also assume familiarity with basic probability and statistics. So most undergraduate \\nstatistics class, like Stat 116 taught here at Stanford, will be more than enough. I'm gonna \\nassume all of you know what random variables are, that all of you know what expectation \\nis, what a variance or a random variable is. And in case of some of you, it's been a while \\nsince you've seen some of this material. At some of the discussion sections, we'll actually \\ngo over some of the prerequisites, sort of as a refresher course under prerequisite class. \\nI'll say a bit more about that later as well.  \\nLastly, I also assume familiarity with basic linear algebra. And again, most undergraduate \\nlinear algebra courses are more than enough. So if you've taken courses like Math 51, \\n103, Math 113 or CS205 at Stanford, that would be more than enough. Basically, I'm \\ngonna assume that all of you know what matrixes and vectors are, that you know how to \\nmultiply matrices and vectors and multiply matrix and matrices, that you know what a \\nmatrix inverse is. If you know what an eigenvector of a matrix is, that'd be even better. \\nBut if you don't quite know or if you're not quite sure, that's fine, too. We'll go over it in \\nthe review sections.\")],\n",
       " 'answer': 'Yes, familiarity with basic probability and statistics is assumed for the class.'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "259e86f7e0b859a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'page': 4, 'source': '../data/MachineLearning-Lecture01.pdf'}, page_content=\"of this class will not be very programming intensive, although we will do some \\nprogramming, mostly in either MATLAB or Octave. I'll say a bit more about that later.  \\nI also assume familiarity with basic probability and statistics. So most undergraduate \\nstatistics class, like Stat 116 taught here at Stanford, will be more than enough. I'm gonna \\nassume all of you know what random variables are, that all of you know what expectation \\nis, what a variance or a random variable is. And in case of some of you, it's been a while \\nsince you've seen some of this material. At some of the discussion sections, we'll actually \\ngo over some of the prerequisites, sort of as a refresher course under prerequisite class. \\nI'll say a bit more about that later as well.  \\nLastly, I also assume familiarity with basic linear algebra. And again, most undergraduate \\nlinear algebra courses are more than enough. So if you've taken courses like Math 51, \\n103, Math 113 or CS205 at Stanford, that would be more than enough. Basically, I'm \\ngonna assume that all of you know what matrixes and vectors are, that you know how to \\nmultiply matrices and vectors and multiply matrix and matrices, that you know what a \\nmatrix inverse is. If you know what an eigenvector of a matrix is, that'd be even better. \\nBut if you don't quite know or if you're not quite sure, that's fine, too. We'll go over it in \\nthe review sections.\")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get first source document\n",
    "result[\"context\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e984a760a8e8a4",
   "metadata": {},
   "source": [
    "### Add history aware retrieval \n",
    "\n",
    "The chain we have built uses the input query directly to retrieve relevant context. But in a conversational setting, the user query might require conversational context to be understood. For example, consider this exchange:\n",
    "\n",
    "> Human: \"Is probability a class topic?\"\n",
    ">\n",
    "> AI: \"Yes, probability is a class topic, as the course assumes familiarity with basic probability and statistics.\"\n",
    ">\n",
    "> Human: \"Why are those prerequisites needed?\"\n",
    "\n",
    "In order to answer the second question, our system needs to understand that \"those\" refers to \"probability and statistics.\"\n",
    "\n",
    "We'll need to update two things about our existing app:\n",
    "\n",
    "1. **Prompt**: Update our prompt to support historical messages as an input.\n",
    "2. **Contextualizing questions**: Add a sub-chain that takes the latest user question and reformulates it in the context of the chat history. This can be thought of simply as building a new \"history aware\" retriever. Whereas before we had:\n",
    "query -> retriever\n",
    "Now we will have:\n",
    "(query, conversation history) -> LLM -> rephrased query -> retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d26f5d11de02aae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_history_aware_retriever\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "\n",
    "contextualize_q_system_prompt = (\n",
    "    \"Given a chat history and the latest user question \"\n",
    "    \"which might reference context in the chat history, \"\n",
    "    \"formulate a standalone question which can be understood \"\n",
    "    \"without the chat history. Do NOT answer the question, \"\n",
    "    \"just reformulate it if needed and otherwise return it as is.\"\n",
    ")\n",
    "\n",
    "contextualize_q_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", contextualize_q_system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "history_aware_retriever = create_history_aware_retriever(\n",
    "    llm, retriever, contextualize_q_prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "05a4076d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['chat_history', 'input'], input_types={'chat_history': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x7f7a217ccf40>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='Given a chat history and the latest user question which might reference context in the chat history, formulate a standalone question which can be understood without the chat history. Do NOT answer the question, just reformulate it if needed and otherwise return it as is.'), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contextualize_q_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d6e5b50167e92",
   "metadata": {},
   "source": [
    "### Your task: Put it together! \n",
    "Build the final chain using history_aware_retriever. Hint: look at how the basic RAG chain was put together. And look here for further reference: \n",
    "https://python.langchain.com/docs/tutorials/qa_chat_history/#adding-chat-history "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed82950",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9bea0ce325637826",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Prompt must accept context as an input variable. Received prompt with input variables: ['chat_history', 'input']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 15\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# TODO: Your task - redefine q_and_a_prompt to take history into account\u001b[39;00m\n\u001b[1;32m      5\u001b[0m q_and_a_prompt \u001b[38;5;241m=\u001b[39m ChatPromptTemplate\u001b[38;5;241m.\u001b[39mfrom_messages(\n\u001b[1;32m      6\u001b[0m     [\n\u001b[1;32m      7\u001b[0m         (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m, contextualize_q_system_prompt),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m     ]\n\u001b[1;32m     11\u001b[0m )\n\u001b[0;32m---> 15\u001b[0m question_answer_chain \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_stuff_documents_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mq_and_a_prompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m rag_chain \u001b[38;5;241m=\u001b[39m create_retrieval_chain(history_aware_retriever, question_answer_chain)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/langchain/chains/combine_documents/stuff.py:79\u001b[0m, in \u001b[0;36mcreate_stuff_documents_chain\u001b[0;34m(llm, prompt, output_parser, document_prompt, document_separator, document_variable_name)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_stuff_documents_chain\u001b[39m(\n\u001b[1;32m     25\u001b[0m     llm: LanguageModelLike,\n\u001b[1;32m     26\u001b[0m     prompt: BasePromptTemplate,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     31\u001b[0m     document_variable_name: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m DOCUMENTS_KEY,\n\u001b[1;32m     32\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Runnable[Dict[\u001b[38;5;28mstr\u001b[39m, Any], Any]:\n\u001b[1;32m     33\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Create a chain for passing a list of Documents to a model.\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \n\u001b[1;32m     35\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;124;03m            chain.invoke({\"context\": docs})\u001b[39;00m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: E501\u001b[39;00m\n\u001b[0;32m---> 79\u001b[0m     \u001b[43m_validate_prompt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdocument_variable_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m     _document_prompt \u001b[38;5;241m=\u001b[39m document_prompt \u001b[38;5;129;01mor\u001b[39;00m DEFAULT_DOCUMENT_PROMPT\n\u001b[1;32m     81\u001b[0m     _output_parser \u001b[38;5;241m=\u001b[39m output_parser \u001b[38;5;129;01mor\u001b[39;00m StrOutputParser()\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/langchain/chains/combine_documents/base.py:27\u001b[0m, in \u001b[0;36m_validate_prompt\u001b[0;34m(prompt, document_variable_name)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_prompt\u001b[39m(prompt: BasePromptTemplate, document_variable_name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m document_variable_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m prompt\u001b[38;5;241m.\u001b[39minput_variables:\n\u001b[0;32m---> 27\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     28\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrompt must accept \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdocument_variable_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m as an input variable. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     29\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived prompt with input variables: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprompt\u001b[38;5;241m.\u001b[39minput_variables\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     30\u001b[0m         )\n",
      "\u001b[0;31mValueError\u001b[0m: Prompt must accept context as an input variable. Received prompt with input variables: ['chat_history', 'input']"
     ]
    }
   ],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "# TODO: Your task - redefine q_and_a_prompt to take history into account\n",
    "q_and_a_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", contextualize_q_system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "question_answer_chain = create_stuff_documents_chain(llm, q_and_a_prompt)\n",
    "\n",
    "rag_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9b11d76c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableBranch(branches=[(RunnableLambda(lambda x: not x.get('chat_history', False)), RunnableLambda(lambda x: x['input'])\n",
       "| VectorStoreRetriever(tags=['Chroma', 'AzureOpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x7f7a0d11f0b0>, search_kwargs={}))], default=ChatPromptTemplate(input_variables=['chat_history', 'input'], input_types={'chat_history': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x7f7a217ccf40>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='Given a chat history and the latest user question which might reference context in the chat history, formulate a standalone question which can be understood without the chat history. Do NOT answer the question, just reformulate it if needed and otherwise return it as is.'), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])\n",
       "| AzureChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x7f7a05fa1070>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7f7a05fa2660>, root_client=<openai.lib.azure.AzureOpenAI object at 0x7f7a0c733e30>, root_async_client=<openai.lib.azure.AsyncAzureOpenAI object at 0x7f7a05fa10a0>, temperature=0.0, model_kwargs={}, openai_api_key=SecretStr('**********'), disabled_params={'parallel_tool_calls': None}, azure_endpoint='https://ait24-openai.openai.azure.com/', deployment_name='gpt-4o', openai_api_version='2024-10-01-preview', openai_api_type='azure')\n",
       "| StrOutputParser()\n",
       "| VectorStoreRetriever(tags=['Chroma', 'AzureOpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x7f7a0d11f0b0>, search_kwargs={})), kwargs={}, config={'run_name': 'chat_retriever_chain'}, config_factories=[])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2ea7b50be29a39",
   "metadata": {},
   "source": [
    "### Setup the simples possible store for message history \n",
    "**_We'll improve on this in the next (agent) section._**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dcdaaf8a93b63bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from langchain_core.messages import BaseMessage\n",
    "\n",
    "chat_history: List[BaseMessage] = []\n",
    "def add_to_history(human_message: str, ai_message: str):\n",
    "    chat_history.extend(\n",
    "        [\n",
    "            HumanMessage(content=human_message),\n",
    "            AIMessage(content=ai_message),\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc8f932505aa7e1",
   "metadata": {},
   "source": [
    "## Run it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bea6709acbbf8fe5",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmessages\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AIMessage, HumanMessage\n\u001b[1;32m      3\u001b[0m ai_msg_1 \u001b[38;5;241m=\u001b[39m rag_chain\u001b[38;5;241m.\u001b[39minvoke({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m\"\u001b[39m: question, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchat_history\u001b[39m\u001b[38;5;124m\"\u001b[39m: chat_history})\n\u001b[0;32m----> 4\u001b[0m add_to_history(question, ai_message\u001b[38;5;241m=\u001b[39m\u001b[43mai_msg_1\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43manswer\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m      6\u001b[0m second_question \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhy are those prerequisites needed?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      7\u001b[0m ai_msg_2 \u001b[38;5;241m=\u001b[39m rag_chain\u001b[38;5;241m.\u001b[39minvoke({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m\"\u001b[39m: second_question, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchat_history\u001b[39m\u001b[38;5;124m\"\u001b[39m: chat_history})\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "\n",
    "ai_msg_1 = rag_chain.invoke({\"input\": question, \"chat_history\": chat_history})\n",
    "add_to_history(question, ai_message=ai_msg_1[\"answer\"])\n",
    "\n",
    "second_question = \"Why are those prerequisites needed?\"\n",
    "ai_msg_2 = rag_chain.invoke({\"input\": second_question, \"chat_history\": chat_history})\n",
    "\n",
    "print(ai_msg_2[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a37c19b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_msg_1 = rag_chain.invoke({\"input\": question, \"chat_history\": chat_history})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "348e34f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'page': 4, 'source': '../data/MachineLearning-Lecture01.pdf'}, page_content=\"of this class will not be very programming intensive, although we will do some \\nprogramming, mostly in either MATLAB or Octave. I'll say a bit more about that later.  \\nI also assume familiarity with basic probability and statistics. So most undergraduate \\nstatistics class, like Stat 116 taught here at Stanford, will be more than enough. I'm gonna \\nassume all of you know what random variables are, that all of you know what expectation \\nis, what a variance or a random variable is. And in case of some of you, it's been a while \\nsince you've seen some of this material. At some of the discussion sections, we'll actually \\ngo over some of the prerequisites, sort of as a refresher course under prerequisite class. \\nI'll say a bit more about that later as well.  \\nLastly, I also assume familiarity with basic linear algebra. And again, most undergraduate \\nlinear algebra courses are more than enough. So if you've taken courses like Math 51, \\n103, Math 113 or CS205 at Stanford, that would be more than enough. Basically, I'm \\ngonna assume that all of you know what matrixes and vectors are, that you know how to \\nmultiply matrices and vectors and multiply matrix and matrices, that you know what a \\nmatrix inverse is. If you know what an eigenvector of a matrix is, that'd be even better. \\nBut if you don't quite know or if you're not quite sure, that's fine, too. We'll go over it in \\nthe review sections.\"),\n",
       " Document(metadata={'page': 4, 'source': '../data/MachineLearning-Lecture01.pdf'}, page_content=\"of this class will not be very programming intensive, although we will do some \\nprogramming, mostly in either MATLAB or Octave. I'll say a bit more about that later.  \\nI also assume familiarity with basic probability and statistics. So most undergraduate \\nstatistics class, like Stat 116 taught here at Stanford, will be more than enough. I'm gonna \\nassume all of you know what random variables are, that all of you know what expectation \\nis, what a variance or a random variable is. And in case of some of you, it's been a while \\nsince you've seen some of this material. At some of the discussion sections, we'll actually \\ngo over some of the prerequisites, sort of as a refresher course under prerequisite class. \\nI'll say a bit more about that later as well.  \\nLastly, I also assume familiarity with basic linear algebra. And again, most undergraduate \\nlinear algebra courses are more than enough. So if you've taken courses like Math 51, \\n103, Math 113 or CS205 at Stanford, that would be more than enough. Basically, I'm \\ngonna assume that all of you know what matrixes and vectors are, that you know how to \\nmultiply matrices and vectors and multiply matrix and matrices, that you know what a \\nmatrix inverse is. If you know what an eigenvector of a matrix is, that'd be even better. \\nBut if you don't quite know or if you're not quite sure, that's fine, too. We'll go over it in \\nthe review sections.\"),\n",
       " Document(metadata={'page': 4, 'source': '../data/MachineLearning-Lecture01.pdf'}, page_content=\"of this class will not be very programming intensive, although we will do some \\nprogramming, mostly in either MATLAB or Octave. I'll say a bit more about that later.  \\nI also assume familiarity with basic probability and statistics. So most undergraduate \\nstatistics class, like Stat 116 taught here at Stanford, will be more than enough. I'm gonna \\nassume all of you know what random variables are, that all of you know what expectation \\nis, what a variance or a random variable is. And in case of some of you, it's been a while \\nsince you've seen some of this material. At some of the discussion sections, we'll actually \\ngo over some of the prerequisites, sort of as a refresher course under prerequisite class. \\nI'll say a bit more about that later as well.  \\nLastly, I also assume familiarity with basic linear algebra. And again, most undergraduate \\nlinear algebra courses are more than enough. So if you've taken courses like Math 51, \\n103, Math 113 or CS205 at Stanford, that would be more than enough. Basically, I'm \\ngonna assume that all of you know what matrixes and vectors are, that you know how to \\nmultiply matrices and vectors and multiply matrix and matrices, that you know what a \\nmatrix inverse is. If you know what an eigenvector of a matrix is, that'd be even better. \\nBut if you don't quite know or if you're not quite sure, that's fine, too. We'll go over it in \\nthe review sections.\"),\n",
       " Document(metadata={'page': 4, 'source': '../data/MachineLearning-Lecture01.pdf'}, page_content=\"of this class will not be very programming intensive, although we will do some \\nprogramming, mostly in either MATLAB or Octave. I'll say a bit more about that later.  \\nI also assume familiarity with basic probability and statistics. So most undergraduate \\nstatistics class, like Stat 116 taught here at Stanford, will be more than enough. I'm gonna \\nassume all of you know what random variables are, that all of you know what expectation \\nis, what a variance or a random variable is. And in case of some of you, it's been a while \\nsince you've seen some of this material. At some of the discussion sections, we'll actually \\ngo over some of the prerequisites, sort of as a refresher course under prerequisite class. \\nI'll say a bit more about that later as well.  \\nLastly, I also assume familiarity with basic linear algebra. And again, most undergraduate \\nlinear algebra courses are more than enough. So if you've taken courses like Math 51, \\n103, Math 113 or CS205 at Stanford, that would be more than enough. Basically, I'm \\ngonna assume that all of you know what matrixes and vectors are, that you know how to \\nmultiply matrices and vectors and multiply matrix and matrices, that you know what a \\nmatrix inverse is. If you know what an eigenvector of a matrix is, that'd be even better. \\nBut if you don't quite know or if you're not quite sure, that's fine, too. We'll go over it in \\nthe review sections.\")]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_msg_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe606c6ff5fb541",
   "metadata": {},
   "source": [
    "#### Have a look at the trace in LangSmith\n",
    "Example: https://smith.langchain.com/public/7cfa0ffd-90ae-4aa3-8a5a-be7479010a17/r"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
