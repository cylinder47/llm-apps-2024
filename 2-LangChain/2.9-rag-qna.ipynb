{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "943ea36a1082641e",
   "metadata": {},
   "source": [
    "# 2.5 RAG Question & Answering\n",
    "\n",
    "![RAG - query pipeline](https://python.langchain.com/assets/images/rag_retrieval_generation-1046a4668d6bb08786ef73c56d4f228a.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9dd64db952da1d",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "### Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e800faf4e660819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install python-dotenv~=1.0 docarray~=0.40.0 pypdf~=5.1 --upgrade --quiet\n",
    "%pip install chromadb~=0.5.18 sentence-transformers~=3.3 --upgrade --quiet \n",
    "%pip install langchain~=0.3.7 langchain_openai~=0.2.6 langchain_community~=0.3.5 --upgrade --quiet\n",
    "\n",
    "# If running locally, you can do this instead:\n",
    "#%pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23db6d4042f86418",
   "metadata": {},
   "source": [
    "### Load environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9f00cf70a4e8556",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "# If running in Google Colab, you can use this code instead:\n",
    "# from google.colab import userdata\n",
    "# os.environ[\"AZURE_OPENAI_API_KEY\"] = userdata.get(\"AZURE_OPENAI_API_KEY\")\n",
    "# os.environ[\"AZURE_OPENAI_ENDPOINT\"] = userdata.get(\"AZURE_OPENAI_ENDPOINT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3d11e1151a7e80",
   "metadata": {},
   "source": [
    "### Setup Chat Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba095904eb63506",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureChatOpenAI, AzureOpenAIEmbeddings\n",
    "api_version = \"2024-10-01-preview\"\n",
    "llm = AzureChatOpenAI(deployment_name=\"gpt-4o\", temperature=0.0, openai_api_version=api_version)\n",
    "embedding_model = AzureOpenAIEmbeddings(model=\"text-embedding-3-large\", openai_api_version=api_version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0dcb326c5b015b",
   "metadata": {},
   "source": [
    "### Setup LangSmith tracing for this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3b906942dc243b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# API key etc is in the .env file\n",
    "# my_name = \"Totoro\"\n",
    "# os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "# os.environ[\"LANGCHAIN_PROJECT\"] = f\"tokyo24-test-{my_name}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca020d02688c907",
   "metadata": {},
   "source": [
    "### Setup path to data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2a050a3283e5523",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../data\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bde3aec39acd7df",
   "metadata": {},
   "source": [
    "## Initialize VectorDB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3bd1965176d16fc",
   "metadata": {},
   "source": [
    "We've discussed `Document Loading` and `Splitting` as well as `Indexing` and `Retrieval` already.\n",
    "\n",
    "Let's load our vectorDB and set it up as in chapter 2.3. _If you already have a persisted vectorDB, you can skip to \"Vector DB\" below._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50b486cfefcaa04",
   "metadata": {},
   "source": [
    "### Load docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1bfd8e7e18c145ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "# Load PDFs\n",
    "loaders = [\n",
    "    PyPDFLoader(f\"{data_path}/MachineLearning-Lecture01.pdf\"),\n",
    "    PyPDFLoader(f\"{data_path}/MachineLearning-Lecture01.pdf\"),\n",
    "    PyPDFLoader(f\"{data_path}/MachineLearning-Lecture03.pdf\")\n",
    "]\n",
    "docs = []\n",
    "for loader in loaders:\n",
    "    docs.extend(loader.load())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468772c910d8752f",
   "metadata": {},
   "source": [
    "### Split docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2e7b06813bc6b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 1500,\n",
    "    chunk_overlap = 150\n",
    ")\n",
    "splits = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ac9e1802663883",
   "metadata": {},
   "source": [
    "### Vector DB - Indexing / Store\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "522653aabd8bc7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "# Optional persist_directory to save the database\n",
    "persist_directory = './db/chroma-ML-docs/'\n",
    "\n",
    "vectordb = Chroma.from_documents(\n",
    "    collection_name=\"ml_docs\",\n",
    "    documents=splits,\n",
    "    embedding=embedding_model,\n",
    "    #persist_directory=persist_directory # Optionally persist the database\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58985b34dd50ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161\n"
     ]
    }
   ],
   "source": [
    "print(vectordb._collection.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2149ee7c35c12b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"What are major topics for this class?\"\n",
    "docs = vectordb.similarity_search(question,k=3)\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdafbc5f8a2ae265",
   "metadata": {},
   "source": [
    "## Create a RAG chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f793332685cd31a",
   "metadata": {},
   "source": [
    "### Simple RAG chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5e055290e6210df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "def format_docs(docs: List[Document]) -> str:\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "# Setup chain using LCEL\n",
    "qa_chain = (\n",
    "        vectordb.as_retriever()\n",
    "        | format_docs \n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76e971446695d82f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This passage seems to be from a lecture or a course introduction, possibly related to a machine learning class. The speaker shares an anecdote about a former student who found the course valuable, particularly because of learning MATLAB, which is a programming environment often used for numerical computing and data analysis. The speaker emphasizes the importance of MATLAB and mentions that there will be a tutorial for those unfamiliar with it.\\n\\nThe passage also outlines the structure and purpose of the discussion sections in the course. These sections, led by teaching assistants, are optional and will be recorded for those who cannot attend. Initially, they will cover prerequisites like probability, statistics, and algebra to help students refresh their knowledge. Later in the course, the discussion sections will delve into extensions of the main lecture material, providing additional insights into the vast field of machine learning.\\n\\nOverall, the passage highlights the practical applications of the course content and the resources available to students to enhance their learning experience.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_chain.invoke(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9586e5c7b990ae0e",
   "metadata": {},
   "source": [
    "### Using a prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "648cec5d45827242",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "# Build prompt\n",
    "system_template = \"\"\"Use the following pieces of context to answer the question. If you don't know the answer, just say that you don't know, don't try to make up an answer. Use three sentences maximum. Keep the answer as concise as possible. Always say \"thanks for asking!\" at the end of the answer. \n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\"\"\"\n",
    "q_and_a_prompt = ChatPromptTemplate([\n",
    "    (\"system\", system_template),\n",
    "    (\"human\", \"{input}\"),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c95908ceca83750",
   "metadata": {},
   "source": [
    "#### Build a chain with the prompt, injecting the context and question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ceb03ec6f26c643f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "# Setup chain using LCEL\n",
    "qa_chain = (\n",
    "    { # This is a shorthand for a RunnableMap / RunnableParallel\n",
    "        \"context\": vectordb.as_retriever() | format_docs,\n",
    "        \"input\": RunnablePassthrough(),\n",
    "    }\n",
    "    | q_and_a_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b21226307cc72b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Is probability a class topic?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "58245b263e4b0f1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Yes, probability is a class topic, as the course assumes familiarity with basic probability and statistics. Thanks for asking!'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_chain.invoke(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51fde161da26fb7",
   "metadata": {},
   "source": [
    "### Alternative - using helper functions to create the chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e318f24122264f82",
   "metadata": {},
   "source": [
    "#### Create the alternative chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c8eb4278965d02e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "combine_docs_chain = create_stuff_documents_chain(llm, q_and_a_prompt)\n",
    "alt_rag_chain = create_retrieval_chain(vectordb.as_retriever(), combine_docs_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "74eedc34d62f9252",
   "metadata": {},
   "outputs": [],
   "source": [
    "alt_result = alt_rag_chain.invoke({\"input\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "826006c239d636de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Yes, probability is a class topic, as the course assumes familiarity with basic probability and statistics. Thanks for asking!'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alt_result[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "259e86f7e0b859a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'page': 4, 'source': '../data/MachineLearning-Lecture01.pdf'}, page_content=\"of this class will not be very programming intensive, although we will do some \\nprogramming, mostly in either MATLAB or Octave. I'll say a bit more about that later.  \\nI also assume familiarity with basic probability and statistics. So most undergraduate \\nstatistics class, like Stat 116 taught here at Stanford, will be more than enough. I'm gonna \\nassume all of you know what random variables are, that all of you know what expectation \\nis, what a variance or a random variable is. And in case of some of you, it's been a while \\nsince you've seen some of this material. At some of the discussion sections, we'll actually \\ngo over some of the prerequisites, sort of as a refresher course under prerequisite class. \\nI'll say a bit more about that later as well.  \\nLastly, I also assume familiarity with basic linear algebra. And again, most undergraduate \\nlinear algebra courses are more than enough. So if you've taken courses like Math 51, \\n103, Math 113 or CS205 at Stanford, that would be more than enough. Basically, I'm \\ngonna assume that all of you know what matrixes and vectors are, that you know how to \\nmultiply matrices and vectors and multiply matrix and matrices, that you know what a \\nmatrix inverse is. If you know what an eigenvector of a matrix is, that'd be even better. \\nBut if you don't quite know or if you're not quite sure, that's fine, too. We'll go over it in \\nthe review sections.\")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get first source document\n",
    "alt_result[\"context\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe606c6ff5fb541",
   "metadata": {},
   "source": [
    "#### Have a look at the trace in LangSmith\n",
    "Exammple: https://smith.langchain.com/public/6d3ebe1f-fc1e-434d-90b5-f60e2fe1d286/r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9793aef66515ab64",
   "metadata": {},
   "source": [
    "### Next step will add chat memory!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
