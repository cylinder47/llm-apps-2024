{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d647f70",
   "metadata": {},
   "source": [
    "# 2.3 Vectorstores and Embeddings - part 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ea283b48ba2d02",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "### Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1923c8632c5ae63",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install python-dotenv~=1.0 docarray~=0.40.0 pypdf~=5.1 --upgrade --quiet\n",
    "%pip install chromadb~=0.5.18 --upgrade --quiet\n",
    "%pip install langchain~=0.3.7 langchain_openai~=0.2.6 langchain_community~=0.3.5 --upgrade --quiet\n",
    "\n",
    "# If running locally, you can do this instead:\n",
    "#%pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ebd910079fdf0e1",
   "metadata": {},
   "source": [
    "### Load environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7232ee2d67b08532",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "# If running in Google Colab, you can use this code instead:\n",
    "# from google.colab import userdata\n",
    "# os.environ[\"AZURE_OPENAI_API_KEY\"] = userdata.get(\"AZURE_OPENAI_API_KEY\")\n",
    "# os.environ[\"AZURE_OPENAI_ENDPOINT\"] = userdata.get(\"AZURE_OPENAI_ENDPOINT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69864f214519cf2",
   "metadata": {},
   "source": [
    "### Setup Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "955248e30fa1a9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureChatOpenAI, AzureOpenAIEmbeddings\n",
    "api_version = \"2024-10-01-preview\"\n",
    "embedding_model = AzureOpenAIEmbeddings(model=\"text-embedding-3-large\", openai_api_version=api_version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de1416d713e07df",
   "metadata": {},
   "source": [
    "### Setup path to data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "331fe6be96d78c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../data\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460a54b0",
   "metadata": {},
   "source": [
    "We just discussed `Document Loading` and `Splitting`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2437469e",
   "metadata": {
    "height": 234,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "# Load PDF\n",
    "loaders = [\n",
    "    # Duplicate documents on purpose - messy data\n",
    "    PyPDFLoader(f\"{data_path}/MachineLearning-Lecture01.pdf\"),\n",
    "    PyPDFLoader(f\"{data_path}/MachineLearning-Lecture01.pdf\"),\n",
    "    PyPDFLoader(f\"{data_path}/MachineLearning-Lecture02.pdf\"),\n",
    "    PyPDFLoader(f\"{data_path}/MachineLearning-Lecture03.pdf\")\n",
    "]\n",
    "docs = []\n",
    "for loader in loaders:\n",
    "    docs.extend(loader.load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb44bf0d",
   "metadata": {
    "height": 115,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 1500,\n",
    "    chunk_overlap = 150\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b71e46cc",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [],
   "source": [
    "splits = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e061f22d",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "208"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848e26fd",
   "metadata": {},
   "source": [
    "## Embeddings\n",
    "\n",
    "Let's take our splits and embed them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c4099521",
   "metadata": {
    "height": 64,
    "tags": []
   },
   "outputs": [],
   "source": [
    "sentence1 = \"i like dogs\"\n",
    "sentence2 = \"i like canines\"\n",
    "sentence3 = \"the weather is ugly outside\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d553549a",
   "metadata": {
    "height": 64,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.02029295265674591, -0.014658346772193909, -0.007224570494145155, -0.005373099818825722, 0.022524481639266014, 0.012113010510802269, -0.012991674244403839, -0.003120651701465249, -0.0017503544222563505, 0.04041854292154312]\n"
     ]
    }
   ],
   "source": [
    "embedding1 = embedding_model.embed_query(sentence1)\n",
    "embedding2 = embedding_model.embed_query(sentence2)\n",
    "embedding3 = embedding_model.embed_query(sentence3)\n",
    "\n",
    "print(embedding1[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0cbe9a9e",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1477c3e20377f29",
   "metadata": {},
   "source": [
    "Embedding 1 and 2 should be similar (using NumPy's dot product to calculate similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "49fc0f8f",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8321759221175041"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(embedding1, embedding2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f16c9e6a51b5ef0",
   "metadata": {},
   "source": [
    "But Embedding 3 should differ more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "32a1fac7",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15657078149987852"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(embedding1, embedding3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9dd18328",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11709408419034396"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(embedding2, embedding3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc7b24f",
   "metadata": {},
   "source": [
    "## Vectorstores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "201e6afa",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "93960ac5",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Optional persist_directory to save the database\n",
    "persist_directory = './db/chroma-ML-docs/'\n",
    "\n",
    "# Remove the directory and all files in it recursively if it exists\n",
    "import shutil\n",
    "import os\n",
    "if os.path.exists(persist_directory):    \n",
    "    shutil.rmtree(persist_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "690efd0a",
   "metadata": {
    "height": 98,
    "tags": []
   },
   "outputs": [],
   "source": [
    "vectordb = Chroma.from_documents(\n",
    "    documents=splits,\n",
    "    embedding=embedding_model,\n",
    "    #persist_directory=persist_directory # Optionally persist the database\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f777480c",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208\n"
     ]
    }
   ],
   "source": [
    "print(vectordb._collection.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efca7589",
   "metadata": {},
   "source": [
    "### Similarity Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3e20837d",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [],
   "source": [
    "question = \"is there an email i can ask for help\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f9bde572",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [],
   "source": [
    "docs = vectordb.similarity_search(question,k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "41388af1",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "183434f6",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"cs229-qa@cs.stanford.edu. This goes to an account that's read by all the TAs and me. So \\nrather than sending us email individually, if you send email to this account, it will \\nactually let us get back to you maximally quickly with answers to your questions.  \\nIf you're asking questions about homework problems, please say in the subject line which \\nassignment and which question the email refers to, since that will also help us to route \\nyour question to the appropriate TA or to me appropriately and get the response back to \\nyou quickly.  \\nLet's see. Skipping ahead — let's see — for homework, one midterm, one open and term \\nproject. Notice on the honor code. So one thing that I think will help you to succeed and \\ndo well in this class and even help you to enjoy this class more is if you form a study \\ngroup.  \\nSo start looking around where you're sitting now or at the end of class today, mingle a \\nlittle bit and get to know your classmates. I strongly encourage you to form study groups \\nand sort of have a group of people to study with and have a group of your fellow students \\nto talk over these concepts with. You can also post on the class newsgroup if you want to \\nuse that to try to form a study group.  \\nBut some of the problems sets in this class are reasonably difficult. People that have \\ntaken the class before may tell you they were very difficult. And just I bet it would be \\nmore fun for you, and you'd probably have a better learning experience if you form a\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].page_content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1edb21d8",
   "metadata": {},
   "source": [
    "Let's save this so we can use it later!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefe9f6a",
   "metadata": {},
   "source": [
    "## Failure modes\n",
    "\n",
    "This seems great, and basic similarity search will get you 80% of the way there very easily. \n",
    "\n",
    "But there are some failure modes that can creep up. \n",
    "\n",
    "Here are some edge cases that can arise - we'll fix them in the next class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "df0f29f9",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [],
   "source": [
    "question = \"what did they say about matlab?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "02be97df",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [],
   "source": [
    "docs = vectordb.similarity_search(question,k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9f579e",
   "metadata": {},
   "source": [
    "Notice that we're getting duplicate chunks (because of the duplicate `MachineLearning-Lecture01.pdf` in the index).\n",
    "\n",
    "Semantic search fetches all similar documents, but does not enforce diversity.\n",
    "\n",
    "`docs[0]` and `docs[1]` are indentical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d39f6954",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'page': 8, 'source': '../data/MachineLearning-Lecture01.pdf'}, page_content='those homeworks will be done in either MATLAB or in Octave, which is sort of — I \\nknow some people call it a free version of MATLAB, which it sort of is, sort of isn\\'t.  \\nSo I guess for those of you that haven\\'t seen MATLAB before, and I know most of you \\nhave, MATLAB is I guess part of the programming language that makes it very easy to \\nwrite codes using matrices, to write code for numerical routines, to move data around, to \\nplot data. And it\\'s sort of an extremely easy to learn tool to use for implementing a lot of \\nlearning algorithms.  \\nAnd in case some of you want to work on your own home computer or something if you \\ndon\\'t have a MATLAB license, for the purposes of this class, there\\'s also — [inaudible] \\nwrite that down [inaudible] MATLAB — there\\' s also a software package called Octave \\nthat you can download for free off the Internet. And it has somewhat fewer features than \\nMATLAB, but it\\'s free, and for the purposes of this class, it will work for just about \\neverything.  \\nSo actually I, well, so yeah, just a side comment for those of you that haven\\'t seen \\nMATLAB before I guess, once a colleague of mine at a different university, not at \\nStanford, actually teaches another machine learning course. He\\'s taught it for many years. \\nSo one day, he was in his office, and an old student of his from, like, ten years ago came \\ninto his office and he said, \"Oh, professor, professor, thank you so much for your')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e04e3d1b",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'page': 8, 'source': '../data/MachineLearning-Lecture01.pdf'}, page_content='those homeworks will be done in either MATLAB or in Octave, which is sort of — I \\nknow some people call it a free version of MATLAB, which it sort of is, sort of isn\\'t.  \\nSo I guess for those of you that haven\\'t seen MATLAB before, and I know most of you \\nhave, MATLAB is I guess part of the programming language that makes it very easy to \\nwrite codes using matrices, to write code for numerical routines, to move data around, to \\nplot data. And it\\'s sort of an extremely easy to learn tool to use for implementing a lot of \\nlearning algorithms.  \\nAnd in case some of you want to work on your own home computer or something if you \\ndon\\'t have a MATLAB license, for the purposes of this class, there\\'s also — [inaudible] \\nwrite that down [inaudible] MATLAB — there\\' s also a software package called Octave \\nthat you can download for free off the Internet. And it has somewhat fewer features than \\nMATLAB, but it\\'s free, and for the purposes of this class, it will work for just about \\neverything.  \\nSo actually I, well, so yeah, just a side comment for those of you that haven\\'t seen \\nMATLAB before I guess, once a colleague of mine at a different university, not at \\nStanford, actually teaches another machine learning course. He\\'s taught it for many years. \\nSo one day, he was in his office, and an old student of his from, like, ten years ago came \\ninto his office and he said, \"Oh, professor, professor, thank you so much for your')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3a915d",
   "metadata": {},
   "source": [
    "We can see a new failure mode.\n",
    "\n",
    "The question below asks a question about the third lecture, but includes results from other lectures as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b19135e5",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [],
   "source": [
    "question = \"what did they say about regression in the third lecture?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d434942c",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [],
   "source": [
    "docs = vectordb.similarity_search(question,k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c2c5df59",
   "metadata": {
    "height": 47,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'page': 0, 'source': '../data/MachineLearning-Lecture03.pdf'}\n",
      "{'page': 0, 'source': '../data/MachineLearning-Lecture02.pdf'}\n",
      "{'page': 6, 'source': '../data/MachineLearning-Lecture03.pdf'}\n",
      "{'page': 13, 'source': '../data/MachineLearning-Lecture03.pdf'}\n",
      "{'page': 14, 'source': '../data/MachineLearning-Lecture03.pdf'}\n"
     ]
    }
   ],
   "source": [
    "for doc in docs:\n",
    "    print(doc.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8e6cb50c",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student:It’s the lowest it –  \n",
      "Instructor (Andrew Ng):No, exactly. Right. So zero to the same, this is not the same, \n",
      "right? And the reason is, in logistic regression this is different from before, right? The \n",
      "definition of this H subscript theta of XI is not the same as the definition I was using in \n",
      "the previous lecture. And in particular this is no longer theta transpose XI. This is not a \n",
      "linear function anymore. This is a logistic function of theta transpose XI. Okay? So even \n",
      "though this looks cosmetically similar, even though this is similar on the surface, to the \n",
      "Bastrian descent rule I derived last time for least squares regression this is actually a \n",
      "totally different learning algorithm. Okay? And it turns out that there’s actually no \n",
      "coincidence that you ended up with the same learning rule. We’ll actually talk a bit more \n",
      "about this later when we talk about generalized linear models. But this is one of the most \n",
      "elegant generalized learning models that we’ll see later. That even though we’re using a \n",
      "different model, you actually ended up with what looks like the same learning algorithm \n",
      "and it’s actually no coincidence. Cool.  \n",
      "One last comment as part of a sort of learning process, over here I said I take the \n",
      "derivatives and I ended up with this line. I didn’t want to make you sit through a long \n",
      "algebraic derivation, but later today or later this week, please, do go home and look at our\n"
     ]
    }
   ],
   "source": [
    "print(docs[4].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3dbca56",
   "metadata": {},
   "source": [
    "### How do we fix this?\n",
    "The **retrieval** (2.4) notebook will cover solutions to these problems.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
