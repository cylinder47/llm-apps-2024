{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc925562",
   "metadata": {},
   "source": [
    "# 2.2 Building chains & LangChain Expression Language (LCEL)\n",
    "(Modified version of lesson 2 of https://www.deeplearning.ai/short-courses/functions-tools-agents-langchain/)\n",
    "<br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f7d5bf209f6332",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "### Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "id": "f7658598325ecfd4",
   "metadata": {},
   "source": [
    "%pip install python-dotenv~=1.0 docarray~=0.40.0 pypdf~=5.1 --upgrade --quiet\n",
    "%pip install langchain~=0.3.7 langchain_openai~=0.2.6 langchain_community~=0.3.5 --upgrade --quiet\n",
    "\n",
    "# If running locally, you can do this instead:\n",
    "#%pip install -r ../requirements.txt"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d56bf93adf169433",
   "metadata": {},
   "source": [
    "### Load environment variables"
   ]
  },
  {
   "cell_type": "code",
   "id": "489acb33abdc6cce",
   "metadata": {},
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "# If running in Google Colab, you can use this code instead:\n",
    "# from google.colab import userdata\n",
    "# os.environ[\"AZURE_OPENAI_API_KEY\"] = userdata.get(\"AZURE_OPENAI_API_KEY\")\n",
    "# os.environ[\"AZURE_OPENAI_ENDPOINT\"] = userdata.get(\"AZURE_OPENAI_ENDPOINT\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "77e4a8c71d3c767",
   "metadata": {},
   "source": "### Setup Models"
  },
  {
   "cell_type": "code",
   "id": "a013c346",
   "metadata": {},
   "source": [
    "from langchain_openai import AzureChatOpenAI, AzureOpenAIEmbeddings\n",
    "api_version = \"2024-10-01-preview\"\n",
    "llm = AzureChatOpenAI(deployment_name=\"gpt-4o\", temperature=0.0, api_version=api_version)\n",
    "embedding_model = AzureOpenAIEmbeddings(model=\"text-embedding-3-large\", api_version=api_version)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "e99c432b-b2c9-497b-9912-c9ca4c1e3740",
   "metadata": {},
   "source": [
    "## Simple Chain"
   ]
  },
  {
   "cell_type": "code",
   "id": "6a0be20d-0e00-478c-a844-017cad13af22",
   "metadata": {
    "height": 98
   },
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"tell me a short joke about {topic} {topic}\"\n",
    ")\n",
    "\n",
    "output_parser = StrOutputParser()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "aedf1c1e-b697-47ce-9d81-eaec9192243b",
   "metadata": {
    "height": 30
   },
   "source": [
    "# Build a chain (creates a RunnableSequence)\n",
    "chain = prompt | llm | output_parser"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6df32028-d35f-4392-bb15-ddeec9ee09b5",
   "metadata": {
    "height": 30
   },
   "source": [
    "chain.invoke({\"topic\": \"bears\"})"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d8ba33b5-2ae9-44d7-b023-18c903af571a",
   "metadata": {},
   "source": [
    "## More complex chain\n",
    "\n",
    "And Runnable Map to supply user-provided inputs to the prompt."
   ]
  },
  {
   "cell_type": "code",
   "id": "d036bb8e-8ca7-4dbd-8103-f50a3c8c3af9",
   "metadata": {
    "height": 47
   },
   "source": [
    "from langchain_community.vectorstores import DocArrayInMemorySearch"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8955cff7-f1a2-4f94-ab5b-fcdda0859702",
   "metadata": {
    "height": 113
   },
   "source": [
    "vectorstore = DocArrayInMemorySearch.from_texts(\n",
    "    [\"harrison worked at kensho\", \"bears like to eat honey\"],\n",
    "    embedding=embedding_model\n",
    ")\n",
    "retriever = vectorstore.as_retriever()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2df87934-1697-405c-b460-5e9bfd16c792",
   "metadata": {
    "height": 30
   },
   "source": [
    "retriever.invoke(\"where did harrison work?\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "871cb26b-97b3-4f63-8bb3-523d3e6d117b",
   "metadata": {
    "height": 45
   },
   "source": [
    "retriever.invoke(\"what do bears like to eat\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "127a7fb6-5821-4934-ab56-9e3300516c05",
   "metadata": {
    "height": 130
   },
   "source": [
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "30591182",
   "metadata": {},
   "source": "### Using a RunnableMap perform parallel actions"
  },
  {
   "cell_type": "code",
   "id": "4ec01c56-731c-4e4f-a5f6-493fba953db0",
   "metadata": {
    "height": 30
   },
   "source": [
    "from langchain.schema.runnable import RunnableMap\n",
    "\n",
    "inputs = RunnableMap({\n",
    "    \"context\": lambda x: retriever.get_relevant_documents(x[\"question\"]),\n",
    "    \"question\": lambda x: x[\"question\"]\n",
    "})\n",
    "\n",
    "# Invoking the partial chain to see what we get\n",
    "inputs.invoke({\"question\": \"where did harrison work?\"})"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a9ca6506-826f-4420-8f19-25dd4dbbc1dc",
   "metadata": {
    "height": 96
   },
   "source": [
    "# Using the inputs (map) to build a chain\n",
    "chain = inputs | prompt | llm | output_parser"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "707d1319-8840-4ed5-b4a4-a2a128799db6",
   "metadata": {
    "height": 30
   },
   "source": [
    "chain.invoke({\"question\": \"where did harrison work?\"})"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "eec59c3b-33e7-437f-9b8b-b4652bc3b863",
   "metadata": {},
   "source": [
    "## Bind - reusing and extending a component (Runnable)\n",
    "\n",
    "### Bind with tools\n",
    "Read more here:\n",
    "* https://python.langchain.com/docs/concepts/tool_calling/#tool-execution\n",
    "* https://python.langchain.com/docs/how_to/tool_calling/"
   ]
  },
  {
   "cell_type": "code",
   "id": "f3efed3b-6d4c-42a4-9692-0cc4596f530b",
   "metadata": {
    "height": 300
   },
   "source": [
    "#Define a tool from a function\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def weather_search(airport_code: str) -> str:\n",
    "    \"\"\"Search for weather given an airport code\"\"\"\n",
    "    return f\"Fetching weather for {airport_code}...\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f8be4721-91d2-4ae6-8fdb-e91dc6ac1bc5",
   "metadata": {
    "height": 115
   },
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"{input}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "function_model = llm.bind_tools([weather_search])\n",
    "# Above we're using a specialized function model that binds the weather_search tool to the model. We can also use the \n",
    "# standard bind function like this (more verbose):\n",
    "#function_model = model.bind(tools=[convert_to_openai_tool(weather_search)], tool_choice=\"required\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e61b095d-9934-41b8-a794-a9dd57e9c733",
   "metadata": {
    "height": 30
   },
   "source": [
    "runnable = prompt | function_model"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a638efeb-b5ce-4aa4-8377-3e86597a03ab",
   "metadata": {
    "height": 30
   },
   "source": [
    "result = runnable.invoke({\"input\": \"what is the weather in sf\"})"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c0b9b822",
   "metadata": {},
   "source": [
    "print(result.tool_calls)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "bebc0c55-48c2-4105-90ec-7297553b8e6a",
   "metadata": {},
   "source": [
    "## Fallbacks"
   ]
  },
  {
   "cell_type": "code",
   "id": "aa0b1ea2-7aef-4449-a553-426cb8c5aa30",
   "metadata": {
    "height": 47
   },
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "df432efe-9415-42e3-ab57-ecf4d439f369",
   "metadata": {
    "height": 115
   },
   "source": [
    "simple_model = llm.bind(\n",
    "    temperature=0, \n",
    "    model=\"gpt-4o-mini\"\n",
    ")\n",
    "simple_chain = simple_model | JsonOutputParser()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "441928c5-8712-45c5-bfdf-6f51634198a7",
   "metadata": {
    "height": 45
   },
   "source": [
    "challenge = \"write three poems in a json blob, where each poem is a json blob of a title, author, and first line\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "0739e85f-8497-4471-8ec9-17e958d80771",
   "metadata": {
    "height": 30
   },
   "source": [
    "# Invoking the model directly and note the response\n",
    "simple_model.invoke(challenge)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "3a20d15c-dc8a-4b6d-a423-a5f814425219",
   "metadata": {},
   "source": [
    "**Note**: The next line is expected to fail, since the model is too basic."
   ]
  },
  {
   "cell_type": "code",
   "id": "2a5e8492-0927-4a3a-b939-947826246330",
   "metadata": {
    "height": 30
   },
   "source": [
    "simple_chain.invoke(challenge) # EXPECTED TO FAIL"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "427f1a4c939b5581",
   "metadata": {},
   "source": [
    "### Try using a more advanced (chat) model instead"
   ]
  },
  {
   "cell_type": "code",
   "id": "6814143b-4a35-4d29-bd32-ba461274bcbf",
   "metadata": {
    "height": 47
   },
   "source": [
    "json_model = simple_model.bind(response_format={\"type\": \"json_object\"})\n",
    "json_chain = llm | JsonOutputParser()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f55f04cf-0217-4106-b41f-0e0661d12c27",
   "metadata": {
    "height": 30
   },
   "source": [
    "json_chain.invoke(challenge)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "948ac408214eda43",
   "metadata": {},
   "source": [
    "### Using a fallback for the simpler chain"
   ]
  },
  {
   "cell_type": "code",
   "id": "b5d3f035-b18d-4cba-854d-a43ef8554e48",
   "metadata": {
    "height": 30
   },
   "source": [
    "final_chain = simple_chain.with_fallbacks([json_chain])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9a09fe6a-548c-412d-9468-9efe2b49f7c9",
   "metadata": {
    "height": 30
   },
   "source": [
    "final_chain.invoke(challenge)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "3fcfdda0-3db2-4073-a647-f2d62c460349",
   "metadata": {},
   "source": [
    "## Runnable Interface - methods common to all Runnable components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a0818a",
   "metadata": {},
   "source": [
    "### Chain composition"
   ]
  },
  {
   "cell_type": "code",
   "id": "33b3b27f-b5a0-4db5-a1b0-20754437a47e",
   "metadata": {
    "height": 132
   },
   "source": [
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"Tell me a short joke about {topic}\"\n",
    ")\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "chain = prompt | llm | output_parser"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d6bc81a6",
   "metadata": {},
   "source": [
    "### Invoke - execute a chain or runnable"
   ]
  },
  {
   "cell_type": "code",
   "id": "48c8cabf-ea55-4448-b070-3ec22942c559",
   "metadata": {
    "height": 30
   },
   "source": [
    "chain.invoke({\"topic\": \"bears\"})"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "e6dd0384",
   "metadata": {},
   "source": [
    "### Batch - run multiple operations in parallel"
   ]
  },
  {
   "cell_type": "code",
   "id": "cc58bdb4-a896-46ba-90c4-1b333245229a",
   "metadata": {
    "height": 30
   },
   "source": [
    "chain.batch([{\"topic\": \"bears\"}, {\"topic\": \"frogs\"}])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "cca82c36",
   "metadata": {},
   "source": [
    "### Streamed response"
   ]
  },
  {
   "cell_type": "code",
   "id": "8a069d61-0a67-4368-b7c4-367262267bb8",
   "metadata": {
    "height": 47
   },
   "source": [
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"Tell me an elaborate joke about {topic}\"\n",
    ")\n",
    "chain = prompt | llm | output_parser\n",
    "\n",
    "for chunk in chain.stream({\"topic\": \"bears\"}):\n",
    "    print(chunk, end=\"|\", flush=True)\n",
    "    "
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d1b3841e",
   "metadata": {},
   "source": [
    "### There are also async version - read more here:\n",
    "https://python.langchain.com/docs/how_to/lcel_cheatsheet/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
