{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc925562",
   "metadata": {},
   "source": [
    "# 2.2 Building chains & LangChain Expression Language (LCEL)\n",
    "(Modified version of lesson 2 of https://www.deeplearning.ai/short-courses/functions-tools-agents-langchain/)\n",
    "<br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f7d5bf209f6332",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "### Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7658598325ecfd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install python-dotenv~=1.0 docarray~=0.40.0 pypdf~=5.1 --upgrade --quiet\n",
    "%pip install langchain~=0.3.7 langchain_openai~=0.2.6 langchain_community~=0.3.5 --upgrade --quiet\n",
    "\n",
    "# If running locally, you can do this instead:\n",
    "#%pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56bf93adf169433",
   "metadata": {},
   "source": [
    "### Load environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "489acb33abdc6cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "# If running in Google Colab, you can use this code instead:\n",
    "# from google.colab import userdata\n",
    "# os.environ[\"AZURE_OPENAI_API_KEY\"] = userdata.get(\"AZURE_OPENAI_API_KEY\")\n",
    "# os.environ[\"AZURE_OPENAI_ENDPOINT\"] = userdata.get(\"AZURE_OPENAI_ENDPOINT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e4a8c71d3c767",
   "metadata": {},
   "source": [
    "### Setup Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a013c346",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureChatOpenAI, AzureOpenAIEmbeddings\n",
    "api_version = \"2024-10-01-preview\"\n",
    "llm = AzureChatOpenAI(deployment_name=\"gpt-4o\", temperature=0.0, openai_api_version=api_version)\n",
    "embedding_model = AzureOpenAIEmbeddings(model=\"text-embedding-3-large\", openai_api_version=api_version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99c432b-b2c9-497b-9912-c9ca4c1e3740",
   "metadata": {},
   "source": [
    "## Simple Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a0be20d-0e00-478c-a844-017cad13af22",
   "metadata": {
    "height": 98
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"tell me a short joke about {topic} {topic}\"\n",
    ")\n",
    "\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aedf1c1e-b697-47ce-9d81-eaec9192243b",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "# Build a chain (creates a RunnableSequence)\n",
    "chain = prompt | llm | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6df32028-d35f-4392-bb15-ddeec9ee09b5",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Why do bears never get lost?\\n\\nBecause they always follow the right koala-fications!'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"topic\": \"bears\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ba33b5-2ae9-44d7-b023-18c903af571a",
   "metadata": {},
   "source": [
    "## More complex chain\n",
    "\n",
    "And Runnable Map to supply user-provided inputs to the prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d036bb8e-8ca7-4dbd-8103-f50a3c8c3af9",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import DocArrayInMemorySearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8955cff7-f1a2-4f94-ab5b-fcdda0859702",
   "metadata": {
    "height": 113
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vscode/.local/lib/python3.12/site-packages/pydantic/_migration.py:283: UserWarning: `pydantic.error_wrappers:ValidationError` has been moved to `pydantic:ValidationError`.\n",
      "  warnings.warn(f'`{import_path}` has been moved to `{new_location}`.')\n"
     ]
    }
   ],
   "source": [
    "vectorstore = DocArrayInMemorySearch.from_texts(\n",
    "    [\"harrison worked at kensho\", \"bears like to eat honey\"],\n",
    "    embedding=embedding_model\n",
    ")\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2df87934-1697-405c-b460-5e9bfd16c792",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='harrison worked at kensho'),\n",
       " Document(metadata={}, page_content='bears like to eat honey')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(\"where did harrison work?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "871cb26b-97b3-4f63-8bb3-523d3e6d117b",
   "metadata": {
    "height": 45
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='bears like to eat honey'),\n",
       " Document(metadata={}, page_content='harrison worked at kensho')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(\"what do bears like to eat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "127a7fb6-5821-4934-ab56-9e3300516c05",
   "metadata": {
    "height": 130
   },
   "outputs": [],
   "source": [
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30591182",
   "metadata": {},
   "source": [
    "### Using a RunnableMap perform parallel actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ec01c56-731c-4e4f-a5f6-493fba953db0",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12850/2193380366.py:4: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  \"context\": lambda x: retriever.get_relevant_documents(x[\"question\"]),\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'context': [Document(metadata={}, page_content='harrison worked at kensho'),\n",
       "  Document(metadata={}, page_content='bears like to eat honey')],\n",
       " 'question': 'where did harrison work?'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.schema.runnable import RunnableMap\n",
    "\n",
    "inputs = RunnableMap({\n",
    "    \"context\": lambda x: retriever.get_relevant_documents(x[\"question\"]),\n",
    "    \"question\": lambda x: x[\"question\"]\n",
    "})\n",
    "\n",
    "# Invoking the partial chain to see what we get\n",
    "inputs.invoke({\"question\": \"where did harrison work?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9ca6506-826f-4420-8f19-25dd4dbbc1dc",
   "metadata": {
    "height": 96
   },
   "outputs": [],
   "source": [
    "# Using the inputs (map) to build a chain\n",
    "chain = inputs | prompt | llm | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "707d1319-8840-4ed5-b4a4-a2a128799db6",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Harrison worked at Kensho.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"question\": \"where did harrison work?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec59c3b-33e7-437f-9b8b-b4652bc3b863",
   "metadata": {},
   "source": [
    "## Bind - reusing and extending a component (Runnable)\n",
    "\n",
    "### Bind with tools\n",
    "Read more here:\n",
    "* https://python.langchain.com/docs/concepts/tool_calling/#tool-execution\n",
    "* https://python.langchain.com/docs/how_to/tool_calling/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f3efed3b-6d4c-42a4-9692-0cc4596f530b",
   "metadata": {
    "height": 300
   },
   "outputs": [],
   "source": [
    "#Define a tool from a function\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def weather_search(airport_code: str) -> str:\n",
    "    \"\"\"Search for weather given an airport code\"\"\"\n",
    "    return f\"Fetching weather for {airport_code}...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f8be4721-91d2-4ae6-8fdb-e91dc6ac1bc5",
   "metadata": {
    "height": 115
   },
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"{input}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "function_model = llm.bind_tools([weather_search])\n",
    "# Above we're using a specialized function model that binds the weather_search tool to the model. We can also use the \n",
    "# standard bind function like this (more verbose):\n",
    "#function_model = model.bind(tools=[convert_to_openai_tool(weather_search)], tool_choice=\"required\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e61b095d-9934-41b8-a794-a9dd57e9c733",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "runnable = prompt | function_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a638efeb-b5ce-4aa4-8377-3e86597a03ab",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "result = runnable.invoke({\"input\": \"what is the weather in sf\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c0b9b822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'weather_search', 'args': {'airport_code': 'SFO'}, 'id': 'call_muz0jFyaL53bDJuW7Xf9WV8D', 'type': 'tool_call'}]\n"
     ]
    }
   ],
   "source": [
    "print(result.tool_calls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cf00adb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='' additional_kwargs={'tool_calls': [{'id': 'call_muz0jFyaL53bDJuW7Xf9WV8D', 'function': {'arguments': '{\"airport_code\":\"SFO\"}', 'name': 'weather_search'}, 'type': 'function'}], 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 52, 'total_tokens': 68, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_04751d0b65', 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'tool_calls', 'logprobs': None, 'content_filter_results': {}} id='run-11780983-d692-4496-a128-35d104bfd15b-0' tool_calls=[{'name': 'weather_search', 'args': {'airport_code': 'SFO'}, 'id': 'call_muz0jFyaL53bDJuW7Xf9WV8D', 'type': 'tool_call'}] usage_metadata={'input_tokens': 52, 'output_tokens': 16, 'total_tokens': 68, 'input_token_details': {}, 'output_token_details': {}}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebc0c55-48c2-4105-90ec-7297553b8e6a",
   "metadata": {},
   "source": [
    "## Fallbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aa0b1ea2-7aef-4449-a553-426cb8c5aa30",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "df432efe-9415-42e3-ab57-ecf4d439f369",
   "metadata": {
    "height": 115
   },
   "outputs": [],
   "source": [
    "simple_model = llm.bind(\n",
    "    temperature=0, \n",
    "    model=\"gpt-4o-mini\"\n",
    ")\n",
    "simple_chain = simple_model | JsonOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "441928c5-8712-45c5-bfdf-6f51634198a7",
   "metadata": {
    "height": 45
   },
   "outputs": [],
   "source": [
    "challenge = \"write three poems in a json blob, where each poem is a json blob of a title, author, and first line\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0739e85f-8497-4471-8ec9-17e958d80771",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='```json\\n{\\n  \"poems\": [\\n    {\\n      \"title\": \"Whispers of Dawn\",\\n      \"author\": \"Emily Rivers\",\\n      \"first_line\": \"In the quiet hush before the sun\"\\n    },\\n    {\\n      \"title\": \"Echoes of the Sea\",\\n      \"author\": \"Liam Shore\",\\n      \"first_line\": \"Waves crash upon the ancient rocks\"\\n    },\\n    {\\n      \"title\": \"Autumn\\'s Embrace\",\\n      \"author\": \"Sophia Maple\",\\n      \"first_line\": \"Leaves dance in the crisp, cool air\"\\n    }\\n  ]\\n}\\n```', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 127, 'prompt_tokens': 31, 'total_tokens': 158, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_04751d0b65', 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'protected_material_code': {'filtered': False, 'detected': False}, 'protected_material_text': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}, id='run-6db45ad6-ffd0-49ea-be6a-0d73156f1d72-0', usage_metadata={'input_tokens': 31, 'output_tokens': 127, 'total_tokens': 158, 'input_token_details': {}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Invoking the model directly and note the response\n",
    "simple_model.invoke(challenge)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a20d15c-dc8a-4b6d-a423-a5f814425219",
   "metadata": {},
   "source": [
    "**Note**: The next line is expected to fail, since the model is too basic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5e8492-0927-4a3a-b939-947826246330",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "simple_chain.invoke(challenge) # EXPECTED TO FAIL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427f1a4c939b5581",
   "metadata": {},
   "source": [
    "### Try using a more advanced (chat) model instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6814143b-4a35-4d29-bd32-ba461274bcbf",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "json_model = simple_model.bind(response_format={\"type\": \"json_object\"})\n",
    "json_chain = llm | JsonOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55f04cf-0217-4106-b41f-0e0661d12c27",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "json_chain.invoke(challenge)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948ac408214eda43",
   "metadata": {},
   "source": [
    "### Using a fallback for the simpler chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d3f035-b18d-4cba-854d-a43ef8554e48",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "final_chain = simple_chain.with_fallbacks([json_chain])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a09fe6a-548c-412d-9468-9efe2b49f7c9",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "final_chain.invoke(challenge)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fcfdda0-3db2-4073-a647-f2d62c460349",
   "metadata": {},
   "source": [
    "## Runnable Interface - methods common to all Runnable components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a0818a",
   "metadata": {},
   "source": [
    "### Chain composition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "33b3b27f-b5a0-4db5-a1b0-20754437a47e",
   "metadata": {
    "height": 132
   },
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"Tell me a short joke about {topic}\"\n",
    ")\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "chain = prompt | llm | output_parser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6bc81a6",
   "metadata": {},
   "source": [
    "### Invoke - execute a chain or runnable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "48c8cabf-ea55-4448-b070-3ec22942c559",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Why do bears never get lost?\\n\\nBecause they always follow the right koala-fications!'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"topic\": \"bears\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6dd0384",
   "metadata": {},
   "source": [
    "### Batch - run multiple operations in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cc58bdb4-a896-46ba-90c4-1b333245229a",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Why do bears never get lost?\\n\\nBecause they always follow the right koala-fications!',\n",
       " 'Why are frogs so happy? Because they eat whatever bugs them!']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.batch([{\"topic\": \"bears\"}, {\"topic\": \"frogs\"}])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca82c36",
   "metadata": {},
   "source": [
    "### Streamed response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8a069d61-0a67-4368-b7c4-367262267bb8",
   "metadata": {
    "height": 47
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "||Sure|,| here's| an| elaborate| bear| joke| for| you|:\n",
      "\n",
      "|Once| upon| a| time|,| deep| in| the| heart| of| the| forest|,| there| was| a| bear| named| Barry|.| Barry| was| not| your| average| bear|;| he| was| a| bear| with| a| dream|.| He| wanted| to| become| a| stand|-up| comedian|.| Every| day|,| Barry| would| practice| his| jokes| in| front| of| the| other| animals|,| but| they| never| seemed| to| laugh|.| The| squirrels| would| just| chatter| nerv|ously|,| the| deer| would| stare| blank|ly|,| and| the| rabbits| would| hop| away| in| confusion|.\n",
      "\n",
      "|Determ|ined| to| make| his| dream| come| true|,| Barry| decided| to| venture| into| the| city| to| perform| at| a| comedy| club|.| He| donn|ed| a| sn|az|zy| bow| tie|,| grabbed| his| best| jokes|,| and| set| off| on| his| journey|.| As| he| approached| the| city|,| he| realized| he| needed| a| disguise| to| blend| in| with| the| humans|.| So|,| he| put| on| a| trench| coat| and| a| fed|ora|,| hoping| no| one| would| notice| he| was| a| bear|.\n",
      "\n",
      "|When| Barry| arrived| at| the| comedy| club|,| he| signed| up| for| the| open| mic| night|.| The| host|,| a| seasoned| comedian| named| Chuck|,| was| skeptical| but| intrigued| by| the| mysterious| newcomer| in| the| trench| coat|.| As| Barry| took| the| stage|,| the| audience| fell| silent|,| curious| about| the| peculiar| figure| before| them|.\n",
      "\n",
      "|Barry| started| with| his| first| joke|:| \"|Why| don't| bears| wear| shoes|?| Because| they| have| bear| feet|!\"| The| audience| chuck|led| politely|.| Encour|aged|,| Barry| continued|,| \"|What| do| you| call| a| bear| with| no| teeth|?| A| gummy| bear|!\"| This| time|,| the| laughter| was| a| bit| louder|.\n",
      "\n",
      "|Feeling| more| confident|,| Barry| decided| to| share| his| personal| favorite|:| \"|Why| did| the| bear| sit| on| the| clock|?| Because| he| wanted| to| be| on| time|!\"| The| crowd| erupted| in| laughter|,| and| Barry|'s| heart| soared|.| He| was| finally| living| his| dream|.\n",
      "\n",
      "|As| the| night| went| on|,| Barry|'s| jokes| got| better| and| better|.| He| talked| about| the| struggles| of| finding| a| good| cave| in| a| competitive| real| estate| market|,| the| challenges| of| h|ibern|ating| with| noisy| neighbors|,| and| the| awkward|ness| of| accidentally| wandering| into| a| campsite|.\n",
      "\n",
      "|By| the| end| of| his| set|,| the| audience| was| in| stitches|,| and| Barry| received| a| standing| ov|ation|.| Chuck|,| the| host|,| approached| him| and| said|,| \"|Barry|,| you're| the| funniest| bear| I've| ever| seen|!| How| about| a| regular| spot| here| at| the| club|?\"\n",
      "\n",
      "|Barry| was| over|joy|ed|.| He| had| not| only| achieved| his| dream| but| had| also| become| the| first| bear| comedian| in| the| city|.| From| that| day| on|,| Barry| the| Bear| was| a| comedy| sensation|,| proving| that| with| a| little| determination| and| a| lot| of| humor|,| even| a| bear| can| make| it| big| in| the| world| of| stand|-up| comedy|.| And| as| for| the| other| animals| back| in| the| forest|?| They| finally| got| the| joke|.||"
     ]
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"Tell me an elaborate joke about {topic}\"\n",
    ")\n",
    "chain = prompt | llm | output_parser\n",
    "\n",
    "for chunk in chain.stream({\"topic\": \"bears\"}):\n",
    "    print(chunk, end=\"|\", flush=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b3841e",
   "metadata": {},
   "source": [
    "### There are also async version - read more here:\n",
    "https://python.langchain.com/docs/how_to/lcel_cheatsheet/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
