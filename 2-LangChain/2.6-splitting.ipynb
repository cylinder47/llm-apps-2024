{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3fc35a165d3c6fa",
   "metadata": {},
   "source": [
    "# 2.2 Document Splitting\n",
    "\n",
    "May seem simple, but it can be a complex process that requires some thought and planning.\n",
    "\n",
    "\n",
    "![Splitting](https://python.langchain.com/assets/images/text_splitters-7961ccc13e05e2fd7f7f58048e082f47.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25890984a48323c",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "### Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b362719e0f81cf6e",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install python-dotenv~=1.0 docarray~=0.40.0 pypdf~=5.1 --upgrade --quiet\n",
    "%pip install langchain~=0.3.7 langchain_openai~=0.2.6 langchain_community~=0.3.5 --upgrade --quiet\n",
    "\n",
    "# If running locally, you can do this instead:\n",
    "#%pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf68e301e626de9",
   "metadata": {},
   "source": [
    "### Load environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ff0f350df68b15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "# If running in Google Colab, you can use this code instead:\n",
    "# from google.colab import userdata\n",
    "# os.environ[\"AZURE_OPENAI_API_KEY\"] = userdata.get(\"AZURE_OPENAI_API_KEY\")\n",
    "# os.environ[\"AZURE_OPENAI_ENDPOINT\"] = userdata.get(\"AZURE_OPENAI_ENDPOINT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a34265170f5968",
   "metadata": {},
   "source": [
    "### Setup path to data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "902a48e7b8e82b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../data\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41546e17c0de2505",
   "metadata": {},
   "source": [
    "## Basic splitting\n",
    "\n",
    "The most intuitive strategy is to split documents based on their length. This simple yet effective approach ensures that each chunk doesn't exceed a specified size limit. \n",
    "\n",
    "Key benefits of length-based splitting:\n",
    "\n",
    "- Straightforward implementation\n",
    "- Consistent chunk sizes\n",
    "- Easily adaptable to different model requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2266f24b84f4bbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "daff4fc44158cdb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size =27\n",
    "chunk_overlap = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac92ecd4128b850e",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=chunk_overlap\n",
    ")\n",
    "c_splitter = CharacterTextSplitter(\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=chunk_overlap\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49767f701d372c84",
   "metadata": {},
   "source": [
    "Let's see how the text is split using the `RecursiveCharacterTextSplitter`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f430e46f023f3a1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abcdefghijklmn opqrstuvwxyz']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1 = 'abcdefghijklmn opqrstuvwxyz' # Equal to chunk_size\n",
    "\n",
    "r_splitter.split_text(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa99933886f10ec3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abcdefghijklmnopqrstuvwxyza', 'xyzabcdefg']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2 = 'abcdefghijklmnopqrstuvwxyzabcdefg' # Longer than chunk_size\n",
    "#text2 = 'abcdefghijklmno pqrstuvwxyzabcdefg' # Longer than chunk_size\n",
    "\n",
    "r_splitter.split_text(text2) # Note overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c04b2a5aa949650",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a b c d e f g h i j k l m n', 'm n o p q r s t u v w x y', 'x y z']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text3 = \"a b c d e f g h i j k l m n o p q r s t u v w x y z\"\n",
    "\n",
    "r_splitter.split_text(text3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a1f875f7e51c09",
   "metadata": {},
   "source": [
    "Now, let's see how the text is split using the `CharacterTextSplitter` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ff9e84688b392f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a b c d e f g h i j k l m n o p q r s t u v w x y z']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many chunks will be created?\n",
    "c_splitter.split_text(text3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72d0235dcd57b1f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a b c d e f g h i j k l m n', 'm n o p q r s t u v w x y z']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's redefine the splitter to split on spaces\n",
    "c_splitter = CharacterTextSplitter(\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=chunk_overlap,\n",
    "    separator = ' '\n",
    ")\n",
    "c_splitter.split_text(text3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3febcdc0719d640",
   "metadata": {},
   "source": [
    "\n",
    "**Try your own examples!** \n",
    "<br/><br/><br/>\n",
    "\n",
    "----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39506fdddd818845",
   "metadata": {},
   "source": [
    "## Recursive splitting details\n",
    "\n",
    "`RecursiveCharacterTextSplitter` is recommended for generic text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca20a00534286d7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "496"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_text = \"\"\"When writing documents, writers will use document structure to group content. \\\n",
    "This can convey to the reader, which idea's are related. For example, closely related ideas \\\n",
    "are in sentances. Similar ideas are in paragraphs. Paragraphs form a document. \\n\\n  \\\n",
    "Paragraphs are often delimited with a carriage return or two carriage returns. \\\n",
    "Carriage returns are the \"backslash n\" you see embedded in this string. \\\n",
    "Sentences have a period at the end, but also, have a space.\\\n",
    "and words are separated by space.\"\"\"\n",
    "\n",
    "len(some_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e30c3957c271149",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_splitter = CharacterTextSplitter(\n",
    "    chunk_size=450,\n",
    "    chunk_overlap=0,\n",
    "    separator = ' '\n",
    ")\n",
    "r_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=450,\n",
    "    chunk_overlap=0,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"] # These are the default separators\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f2eee6a05df48b9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splits: [448, 46]\n",
      "['When writing documents, writers will use document structure to group content. This can convey to the reader, which idea\\'s are related. For example, closely related ideas are in sentances. Similar ideas are in paragraphs. Paragraphs form a document. \\n\\n Paragraphs are often delimited with a carriage return or two carriage returns. Carriage returns are the \"backslash n\" you see embedded in this string. Sentences have a period at the end, but also,', 'have a space.and words are separated by space.']\n"
     ]
    }
   ],
   "source": [
    "docs = c_splitter.split_text(some_text)\n",
    "\n",
    "print(f\"Splits: {[len(doc) for doc in docs]}\")\n",
    "print(docs)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "80bf717c7b8c332a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splits: [248, 243]\n",
      "[\"When writing documents, writers will use document structure to group content. This can convey to the reader, which idea's are related. For example, closely related ideas are in sentances. Similar ideas are in paragraphs. Paragraphs form a document.\", 'Paragraphs are often delimited with a carriage return or two carriage returns. Carriage returns are the \"backslash n\" you see embedded in this string. Sentences have a period at the end, but also, have a space.and words are separated by space.']\n"
     ]
    }
   ],
   "source": [
    "docs = r_splitter.split_text(some_text)\n",
    "\n",
    "print(f\"Splits: {[len(doc) for doc in docs]}\")\n",
    "print(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64131448590965d",
   "metadata": {},
   "source": [
    "## PDF Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e05b0335efd8871",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "#loader = PyPDFLoader(f\"{data_path}/MachineLearning-Lecture01.pdf\")\n",
    "loader = PyPDFLoader(f\"{data_path}/prop_202425__11.pdf\")\n",
    "loaded_pages = loader.load()\n",
    "\n",
    "content = ' '.join([page.page_content for page in loaded_pages[:20]])\n",
    "len(content)\n",
    "print(content[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c771d662773079c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Try with CharacterTextSplitter\n",
    "# text_splitter = CharacterTextSplitter(\n",
    "#     separator=\"\\n\",\n",
    "#     chunk_size=1000,\n",
    "#     chunk_overlap=150,\n",
    "#     length_function=len\n",
    "# )\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=4000, \n",
    "    chunk_overlap=200\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d22833f8882a2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = text_splitter.split_documents(loaded_pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40099b19a5cf19a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Document splits: {len(docs)}\")\n",
    "print(f\"Loaded pages: {len(loaded_pages)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bbb12a278c2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's print some info about a single page\n",
    "page=3\n",
    "print(f\"Metadata: {docs[page].metadata}\")\n",
    "print(f\"Length: {len(docs[page].page_content)}\")\n",
    "print(f\"Page content (first 100): \\n{docs[page].page_content[:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54dc07a5e1323bec",
   "metadata": {},
   "source": [
    "## Context aware splitting\n",
    "\n",
    "Chunking aims to keep text with common context together.\n",
    "\n",
    "A text splitting often uses sentences or other delimiters to keep related text together but many documents (such as Markdown) have structure (headers) that can be explicitly used in splitting.\n",
    "\n",
    "We can use `MarkdownHeaderTextSplitter` to preserve header metadata in our chunks, as show below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df037cb74e15b6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import MarkdownHeaderTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962d5402082fd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "markdown_document = \"\"\"# Title\\n\\n \\\n",
    "## Chapter 1\\n\\n \\\n",
    "Hi this is Jim\\n\\n Hi this is Joe\\n\\n \\\n",
    "### Section \\n\\n \\\n",
    "Hi this is Lance \\n\\n \n",
    "## Chapter 2\\n\\n \\\n",
    "Hi this is Molly\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9b3977d3ecbe43",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers_to_split_on = [\n",
    "    (\"#\", \"Header 1\"),\n",
    "    (\"##\", \"Header 2\"),\n",
    "    (\"###\", \"Header 3\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c2b588e8c8f8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "markdown_splitter = MarkdownHeaderTextSplitter(\n",
    "    headers_to_split_on=headers_to_split_on\n",
    ")\n",
    "md_header_splits = markdown_splitter.split_text(markdown_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ae6196019afbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "md_header_splits[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df6100e92c0ced2",
   "metadata": {},
   "outputs": [],
   "source": [
    "md_header_splits[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
