{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Retrieval a.k.a. RAG\n",
    "\n",
    "Retrieval is the centerpiece of our retrieval augmented generation (RAG) flow. \n",
    "\n",
    "![RAG - indexing](https://python.langchain.com/assets/images/rag_indexing-8160f90a90a33253d0154659cf7d453f.png)"
   ],
   "id": "c92fb8f010c88f46"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Setup\n",
    "\n",
    "### Install dependencies"
   ],
   "id": "d3879bfdb834293e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%pip install python-dotenv~=1.0 docarray~=0.40.0 pypdf~=5.1 --upgrade --quiet\n",
    "%pip install chromadb~=0.5.18 sentence-transformers~=3.3 lark~=1.2 --upgrade --quiet \n",
    "%pip install langchain~=0.3.7 langchain_openai~=0.2.6 langchain_community~=0.3.5 --upgrade --quiet\n",
    "\n",
    "# If running locally, you can do this instead:\n",
    "#%pip install -r ../requirements.txt"
   ],
   "id": "d88decc865f48d82",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Load environment variables",
   "id": "d2ac40a94d9832c2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "# If running in Google Colab, you can use this code instead:\n",
    "# from google.colab import userdata\n",
    "# os.environ[\"AZURE_OPENAI_API_KEY\"] = userdata.get(\"AZURE_OPENAI_API_KEY\")\n",
    "# os.environ[\"AZURE_OPENAI_ENDPOINT\"] = userdata.get(\"AZURE_OPENAI_ENDPOINT\")"
   ],
   "id": "5665d22198714b71",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Setup Chat Model",
   "id": "e13737536f4e381"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain_openai import AzureChatOpenAI, AzureOpenAIEmbeddings\n",
    "api_version = \"2024-10-01-preview\"\n",
    "llm = AzureChatOpenAI(deployment_name=\"gpt-4o\", temperature=0.0, api_version=api_version)\n",
    "embedding_model = AzureOpenAIEmbeddings(model=\"text-embedding-3-large\", api_version=api_version)"
   ],
   "id": "cba8ccd98ee77d87",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Setup path to data ",
   "id": "832574a6d0c3e64d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "data_path = \"../data\"",
   "id": "f409d95acc8198e0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Vectorstore retrieval\n",
   "id": "2df7b7494e0a856b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Similarity Search",
   "id": "2b8a7bb26c903db6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "texts = [\n",
    "    \"\"\"The Amanita phalloides has a large and imposing epigeous (aboveground) fruiting body (basidiocarp).\"\"\",\n",
    "    \"\"\"A mushroom with a large fruiting body is the Amanita phalloides. Some varieties are all-white.\"\"\",\n",
    "    \"\"\"A. phalloides, a.k.a Death Cap, is one of the most poisonous of all known mushrooms.\"\"\",\n",
    "]\n",
    "\n",
    "smalldb = Chroma.from_texts(texts, embedding=embedding_model)"
   ],
   "id": "5dcb485c68ce4b8e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "question = \"Tell me about all-white mushrooms with large fruiting bodies\"\n",
    "\n",
    "smalldb.similarity_search(question, k=2)"
   ],
   "id": "7cfadac4ea9d6bd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Try again with MMR",
   "id": "fd88f563f59a28bc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "smalldb.max_marginal_relevance_search(question,k=2, fetch_k=3)",
   "id": "fd8617db8fa5733a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Addressing Diversity: Maximum marginal relevance\n",
    "\n",
    "Last class we introduced one problem: how to enforce diversity in the search results.\n",
    " \n",
    "`Maximum marginal relevance` strives to achieve both relevance to the query *and diversity* among the results."
   ],
   "id": "15922aa064cd4229"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Let's setup our vectorDB as before\n",
    "Load ML sample docs and setup Vector DB"
   ],
   "id": "f8b37bf209e80e8c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Load PDFs\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "loaders = [\n",
    "    # Duplicate documents on purpose - messy data\n",
    "    PyPDFLoader(f\"{data_path}/MachineLearning-Lecture01.pdf\"),\n",
    "    PyPDFLoader(f\"{data_path}/MachineLearning-Lecture01.pdf\"),\n",
    "    PyPDFLoader(f\"{data_path}/MachineLearning-Lecture02.pdf\"),\n",
    "    PyPDFLoader(f\"{data_path}/MachineLearning-Lecture03.pdf\")\n",
    "]\n",
    "docs = []\n",
    "for loader in loaders:\n",
    "    docs.extend(loader.load())\n",
    "\n",
    "# Split\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 1500,\n",
    "    chunk_overlap = 150\n",
    ")\n",
    "splits = text_splitter.split_documents(docs)\n",
    "\n",
    "# Setup vector DB\n",
    "persist_directory = './db/chroma-ML-docs/'\n",
    "vectordb = Chroma.from_documents(\n",
    "    collection_name=\"ml_docs\",\n",
    "    documents=splits,\n",
    "    embedding=embedding_model,\n",
    "    #persist_directory=persist_directory # Optionally persist the database\n",
    ")\n",
    "\n",
    "print(vectordb._collection.count())"
   ],
   "id": "155de4b2d44e616f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "question = \"what did they say about matlab?\"\n",
    "docs_ss = vectordb.similarity_search(question,k=3)"
   ],
   "id": "dacc8fe91f837843",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "docs_ss[0].page_content[:100]",
   "id": "405d02b12fa40dd2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "docs_ss[1].page_content[:100]",
   "id": "a4bdf0e8b6353cb9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now, note the difference in results with `MMR`. ",
   "id": "5bcfcad5c19d886b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "docs_mmr = vectordb.max_marginal_relevance_search(question,k=3)",
   "id": "41ef47c5eebf8be5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "docs_mmr[0].page_content[:100]",
   "id": "7c82de8cdec89d41",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "docs_mmr[1].page_content[:100]",
   "id": "58089caf79a124e2",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
